{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fb6160cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import cv2\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15721a",
   "metadata": {},
   "source": [
    "### Data Prep Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "429fb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize dataset structure\n",
    "def summarize_dataset_structure(base_dir=\".\"):\n",
    "    \"\"\"\n",
    "    Summarize how many videos exist in each class folder across train/val/test splits.\n",
    "    Handles nested folder structures (e.g., class -> video -> clips).\n",
    "\n",
    "    Example layout:\n",
    "        base_dir/\n",
    "            train/\n",
    "                Abuse/\n",
    "                    Abuse001_x264/\n",
    "                        Abuse001_x264_0.mp4\n",
    "                        Abuse001_x264_1.mp4\n",
    "                Shoplifting/\n",
    "            val/\n",
    "            test/\n",
    "    \"\"\"\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        split_path = os.path.join(base_dir, split)\n",
    "        if not os.path.exists(split_path):\n",
    "            print(f\"‚ö†Ô∏è Split folder not found: {split_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nüìÇ Stats for split: {split}\")\n",
    "        total_videos = 0\n",
    "\n",
    "        # Iterate over each class folder (Abuse, Shoplifting, etc.)\n",
    "        for cls in sorted(os.listdir(split_path)):\n",
    "            cls_path = os.path.join(split_path, cls)\n",
    "            if not os.path.isdir(cls_path):\n",
    "                continue\n",
    "\n",
    "            video_count = 0\n",
    "\n",
    "            # Go into subdirectories (e.g., Abuse001_x264)\n",
    "            for root, _, files in os.walk(cls_path):\n",
    "                video_files = [\n",
    "                    f for f in files\n",
    "                    if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.npy'))\n",
    "                ]\n",
    "                video_count += len(video_files)\n",
    "\n",
    "            print(f\"  üóÇÔ∏è {cls}: {video_count} video clips\")\n",
    "            total_videos += video_count\n",
    "\n",
    "        print(f\"  ‚û§ Total video clips in '{split}': {total_videos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28d4a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load UCF Crime-style JSON annotations\n",
    "def load_ucf_json(json_path):\n",
    "    \"\"\"\n",
    "    Loads a UCF Crime-style JSON annotation file and converts it\n",
    "    into a flattened pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        json_path (str): Path to the JSON annotation file.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Flattened DataFrame with columns:\n",
    "            ['video', 'duration', 'start', 'end', 'description']\n",
    "    \"\"\"\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    rows = []\n",
    "    for video, info in data.items():\n",
    "        for (ts, sentence) in zip(info.get(\"timestamps\", []), info.get(\"sentences\", [])):\n",
    "            rows.append({\n",
    "                \"video\": video,\n",
    "                \"duration\": info.get(\"duration\", None),\n",
    "                \"start\": ts[0],\n",
    "                \"end\": ts[1],\n",
    "                \"description\": sentence\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecb4d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_clip_paths(df):\n",
    "    \"\"\"\n",
    "    Adds a 'clip_path' column based only on DataFrame columns:\n",
    "    folder/video_basename/video_basename_i.mp4\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): must contain 'folder' and 'video' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: with an extra column 'clip_path'\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Remove .mp4 extension from video to get folder/video base\n",
    "    df[\"video_base\"] = df[\"video\"].str.replace(\".mp4\", \"\", regex=False)\n",
    "\n",
    "    # Get index per unique (folder, video) group ‚Äî i = 0, 1, 2, ...\n",
    "    df[\"clip_idx\"] = df.groupby([\"folder\", \"video\"]).cumcount()\n",
    "\n",
    "    # Construct the relative path\n",
    "    df[\"clip_path\"] = df.apply(\n",
    "        lambda row: f\"{row['folder']}/{row['video_base']}/{row['video_base']}_{row['clip_idx']}.mp4\",\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df.drop(['video_base', 'clip_idx'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c074cc",
   "metadata": {},
   "source": [
    "### SwinBERT: Loading UCA Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d7472-6958-483b-9cfc-fd8777b1bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2498a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../Surveillance-Video-Understanding-main/ucf-annotation/json/UCFCrime_Train.json\"\n",
    "test_file = \"../Surveillance-Video-Understanding-main/ucf-annotation/json/UCFCrime_Test.json\"\n",
    "val_file = \"../Surveillance-Video-Understanding-main/ucf-annotation/json/UCFCrime_Val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_ucf_json(train_file)\n",
    "test_df = load_ucf_json(test_file)\n",
    "val_df = load_ucf_json(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['folder'] = train_df['video'].apply(lambda x: re.match(r'([A-Za-z]+)', x).group(1) if re.match(r'([A-Za-z]+)', x) else None)\n",
    "test_df['folder'] = test_df['video'].apply(lambda x: re.match(r'([A-Za-z]+)', x).group(1) if re.match(r'([A-Za-z]+)', x) else None)\n",
    "val_df['folder'] = val_df['video'].apply(lambda x: re.match(r'([A-Za-z]+)', x).group(1) if re.match(r'([A-Za-z]+)', x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6479a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['video'] = train_df['video']+\".mp4\"\n",
    "test_df['video'] = test_df['video']+\".mp4\"\n",
    "val_df['video'] = val_df['video']+\".mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffde7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = add_clip_paths(train_df)\n",
    "train_df[train_df[\"video\"] == \"Abuse001_x264.mp4\"][[\"folder\", \"video\", \"clip_path\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8eef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = add_clip_paths(test_df)\n",
    "val_df = add_clip_paths(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b457912",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['split'] = 'train'\n",
    "test_df['split'] = 'test'\n",
    "val_df['split'] = 'val'\n",
    "\n",
    "all_annotations = pd.concat([train_df, test_df, val_df], ignore_index=True)\n",
    "\n",
    "# Expringting all annotations to CSV\n",
    "all_annotations.to_csv(\"../uca-dataset/uca_annotations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16559454",
   "metadata": {},
   "source": [
    "### SwinBERT: Preparing UCA Dataset with Clipped Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_videos_from_df(df, source_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Clips videos using MoviePy 2.x API based on 'start' and 'end' times in the DataFrame.\n",
    "    Displays a progress bar and only logs failures or invalid clips.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    total_videos = df['video'].nunique()\n",
    "\n",
    "    print(f\"üé¨ Starting video clipping for {total_videos} unique videos ({len(df)} total clips)...\\n\")\n",
    "\n",
    "    # Group videos first\n",
    "    grouped_videos = list(df.groupby([\"folder\", \"video\"]))\n",
    "\n",
    "    # tqdm progress bar\n",
    "    for (folder, video_name), group in tqdm(grouped_videos, desc=\"Processing videos\", unit=\"video\"):\n",
    "        src_path = os.path.join(source_dir, folder, video_name)\n",
    "        base_name, ext = os.path.splitext(video_name)\n",
    "        dest_subdir = os.path.join(output_dir, folder, base_name)\n",
    "        os.makedirs(dest_subdir, exist_ok=True)\n",
    "\n",
    "        if not os.path.exists(src_path):\n",
    "            print(f\"‚ö†Ô∏è Missing source video: {src_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            video = VideoFileClip(src_path)\n",
    "            for i, row in enumerate(group.itertuples(index=False)):\n",
    "                start = float(row.start)\n",
    "                end = min(float(row.end), video.duration)\n",
    "\n",
    "                # Skip invalid segments\n",
    "                if end <= start:\n",
    "                    print(f\"‚è© Skipping invalid segment ({start:.2f}-{end:.2f}) in {video_name}\")\n",
    "                    continue\n",
    "\n",
    "                clip = video.subclipped(start, end)\n",
    "                dest_path = os.path.join(dest_subdir, f\"{base_name}_{i}.mp4\")\n",
    "\n",
    "                # Silent writing (no MoviePy output spam)\n",
    "                clip.write_videofile(dest_path, audio=False, logger=None)\n",
    "\n",
    "            video.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {src_path}: {e}\")\n",
    "\n",
    "    print(\"\\n‚úÖ All videos processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec59f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_dir = '../original-ucf/Videos'\n",
    "destination_dir = '../uca-dataset'\n",
    "\n",
    "clip_videos_from_df(\n",
    "    df=train_df,\n",
    "    source_dir=source_dir,         \n",
    "    output_dir=destination_dir+\"/train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c3436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_dir = '../original-ucf/Videos'\n",
    "destination_dir = '../uca-dataset'\n",
    "\n",
    "clip_videos_from_df(\n",
    "    df=val_df,\n",
    "    source_dir=source_dir,         \n",
    "    output_dir=destination_dir+\"/val\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f824f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_dir = '../original-ucf/Videos'\n",
    "destination_dir = '../uca-dataset'\n",
    "\n",
    "clip_videos_from_df(\n",
    "    df=test_df,\n",
    "    source_dir=source_dir,         \n",
    "    output_dir=destination_dir+\"/test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f95ba1",
   "metadata": {},
   "source": [
    "#### Validating Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca009964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_duplicates(df, subset_cols=[\"video\", \"start\", \"end\", \"description\"]):\n",
    "    \"\"\"\n",
    "    Checks for duplicate video segments based on selected columns.\n",
    "    Prints how many duplicates exist and which videos have them.\n",
    "    \"\"\"\n",
    "    duplicated_rows = df[df.duplicated(subset=subset_cols, keep=False)]\n",
    "    total_dupes = len(duplicated_rows)\n",
    "\n",
    "    if total_dupes == 0:\n",
    "        print(\"‚úÖ No duplicates found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìä Found {total_dupes} duplicate rows based on {subset_cols}\")\n",
    "\n",
    "    # Count duplicates per video\n",
    "    dupe_counts = (\n",
    "        duplicated_rows.groupby([\"video\", \"start\", \"end\"])\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index(name=\"duplicate_count\")\n",
    "    )\n",
    "\n",
    "    print(\"\\nüéûÔ∏è Videos with duplicate timestamps:\")\n",
    "    display(dupe_counts.head(10))  # show top 10 by default\n",
    "\n",
    "    return duplicated_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_duplicates(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ead174",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_duplicates(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32dc3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_rows = check_for_duplicates(train_df)\n",
    "# These duplicates are present in th original transcripts as well. Leaving them for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93560002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This aligns perfectly with the UCA paper table 3\n",
    "destination_dir = \"../uca-dataset\"\n",
    "summarize_dataset_structure(base_dir=destination_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28387a3f",
   "metadata": {},
   "source": [
    "### SwinBERT: YAML File Creation - Fine Tune SwinBERT on UCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yaml_files(df, output_dir=\"../UCA-Dataset/w-captions/\"):\n",
    "    \"\"\"\n",
    "    Converts UCA annotations CSV into SwinBERT-compatible YAML files for train/val/test.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to CSV file with columns ['clip_path', 'description', 'split'].\n",
    "        output_dir (str): Folder where YAMLs will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Validate required columns\n",
    "    required = {\"clip_path\", \"description\", \"split\"}\n",
    "    if not required.issubset(df.columns):\n",
    "        raise ValueError(f\"CSV must contain columns: {required}\")\n",
    "\n",
    "    # Generate YAML for each split\n",
    "    for split in df[\"split\"].unique():\n",
    "        split_df = df[df[\"split\"] == split]\n",
    "        split_yaml = {\n",
    "            # This is based on file structure in Cloud GPU Instance\n",
    "            f\"{split}_videos\": [os.path.join(\"../UCA-Dataset/w-captions\", p) for p in split_df[\"clip_path\"]],\n",
    "            \"captions\": split_df[\"description\"].tolist()\n",
    "        }\n",
    "\n",
    "        out_path = os.path.join(output_dir, f\"{split}.yaml\")\n",
    "        with open(out_path, \"w\") as f:\n",
    "            yaml.dump(split_yaml, f, default_flow_style=False, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "        print(f\"‚úÖ Saved: {out_path} ({len(split_df)} entries)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99061546",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations = pd.read_csv(\"../UCA-Dataset/uca_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e64d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations['description'] = all_annotations['description'].str.replace('\\n', ' ').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yaml_files(all_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162584dc-68cf-4885-8d34-d99fe266b6d1",
   "metadata": {},
   "source": [
    "###  TEVAD: Aligning data based on UCF to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bab5b5ee-7656-42bb-aa86-55d1f6ae624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original UCF\n",
    "train_ucf = pd.read_csv(\"../../Anomaly_Train.txt\", header=None,\n",
    "    names=[\"path\"])\n",
    "\n",
    "train_ucf['video'] = train_ucf['path'].str.split('/').str[1]\n",
    "\n",
    "test_ucf = pd.read_csv(\"../../Anomaly_Test.txt\", header=None,\n",
    "    names=[\"path\"])\n",
    "\n",
    "test_ucf['video'] = test_ucf['path'].str.split('/').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "43ec4f5f-a1e5-4b32-bf9b-91984479f834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abuse/Abuse028_x264.mp4</td>\n",
       "      <td>Abuse028_x264.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abuse/Abuse030_x264.mp4</td>\n",
       "      <td>Abuse030_x264.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path              video\n",
       "0  Abuse/Abuse028_x264.mp4  Abuse028_x264.mp4\n",
       "1  Abuse/Abuse030_x264.mp4  Abuse030_x264.mp4"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ucf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035d805-d187-4e0e-a028-5da62d70ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: moving all files to a central location\n",
    "src_dir = \"../TEVAD/save/Crime/UCF_ten_crop_i3d_v1\"\n",
    "dest_dir = \"../TEVAD/save/Crime/UCF_all_i3d\"\n",
    "\n",
    "subfolders = [\"UCF_Train_ten_crop_i3d\", \"UCF_Test_ten_crop_i3d\"]\n",
    "\n",
    "for sub in subfolders:\n",
    "    sub_path = os.path.join(src_dir, sub)\n",
    "    files = os.listdir(sub_path)\n",
    "\n",
    "    print(f\"\\nMoving files from: {sub_path}\")\n",
    "\n",
    "    # tqdm progress bar\n",
    "    for file in tqdm(files, desc=f\"Processing {sub}\", unit=\"file\"):\n",
    "        src_path = os.path.join(sub_path, file)\n",
    "        dst_path = os.path.join(dest_dir, file)\n",
    "\n",
    "        if os.path.isfile(src_path):\n",
    "            shutil.move(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a05355ee-c600-4676-b1db-29b70fe6507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = \"../TEVAD/save/Crime/UCF_all_i3d\"\n",
    "train_dir = \"../TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Train_ten_crop_i3d\"\n",
    "test_dir = \"../TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Test_ten_crop_i3d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "be95c7f2-f8f2-4881-b57a-cf7d7cc8e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ucf['split'] = 'train'\n",
    "test_ucf['split'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "33542946-633d-4040-9343-49ab579c84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_ucf, test_ucf])\n",
    "df.drop_duplicates(inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0bc47279-564c-4679-9683-d8aac5891294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    1610\n",
       "test      290\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2ae3b04b-241d-4bff-9cdb-68e8bb496777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['npy_name'] = df['video'].str.replace('.mp4', '_i3d.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f39f1fa5-21ee-421f-adf1-729d2089f8d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1900/1900 [00:18<00:00, 105.26file/s]\n"
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Moving files\", unit=\"file\"):\n",
    "    filename = row['npy_name']\n",
    "    split = row['split']\n",
    "\n",
    "    src_path = os.path.join(src_dir, filename)\n",
    "\n",
    "    # Determine destination\n",
    "    if split in ['train', 'val']:\n",
    "        dst_path = os.path.join(train_dir, filename)\n",
    "    else:  # test\n",
    "        dst_path = os.path.join(test_dir, filename)\n",
    "\n",
    "    # Move if exists\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.move(src_path, dst_path)\n",
    "    else:\n",
    "        print(f\"Missing file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ffa53ce-77dd-47a4-a6ae-9b5de642e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_loc = \"../TEVAD/save/Crime/sent_emb_n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f8e6728-6a60-4484-9f10-56f35857534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emb_name'] = df['video'].str.replace('.mp4', '_emb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bec1d12c-2153-4d0b-8cd8-8ff5ae7f446c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>video</th>\n",
       "      <th>split</th>\n",
       "      <th>npy_name</th>\n",
       "      <th>emb_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [path, video, split, npy_name, emb_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if we missed any embeddings\n",
    "\n",
    "expected = set(df['emb_name'])\n",
    "actual = set(os.listdir(embeddings_loc))\n",
    "missing_files = expected - actual\n",
    "\n",
    "emb_rem = df[df['emb_name'].isin(missing_files)]\n",
    "emb_rem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b45efbdb-9881-4393-bd66-f419bfeef3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb_rem.to_csv(\"Emb.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65179784-c413-4dfd-b2f4-4d11c165bfd2",
   "metadata": {},
   "source": [
    "### TEVAD: Creating UCF Train/Test List and Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3638f6b1-7be8-4d1b-92de-84a8cd553e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_dir = \"/home/ubuntu/uca-virginia/Multimodal-Anomaly-Detection-Survelliance-Videos/TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Train_ten_crop_i3d\"\n",
    "test_base_dir = \"/home/ubuntu/uca-virginia/Multimodal-Anomaly-Detection-Survelliance-Videos/TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Test_ten_crop_i3d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bb63dde9-f993-4e9c-b497-e01fde2dfc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>video</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abuse/Abuse001_x264.mp4</td>\n",
       "      <td>Abuse001_x264.mp4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abuse/Abuse002_x264.mp4</td>\n",
       "      <td>Abuse002_x264.mp4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path              video  split\n",
       "0  Abuse/Abuse001_x264.mp4  Abuse001_x264.mp4  train\n",
       "1  Abuse/Abuse002_x264.mp4  Abuse002_x264.mp4  train"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ucf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1d2ff29f-ce5e-4cf5-bfb2-9a7f4a6796e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ucf['npy_name'] = train_ucf['video'].str.replace('.mp4', '_i3d.npy')\n",
    "train_ucf['is_normal'] = train_ucf['npy_name'].str.startswith(\"Normal_Videos\")\n",
    "\n",
    "train_ucf = train_ucf.sort_values(by='is_normal', ascending=True)\n",
    "train_ucf.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "20fb2305-a630-4e8a-8e40-7a7aef730e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>video</th>\n",
       "      <th>split</th>\n",
       "      <th>npy_name</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>Training_Normal_Videos_Anomaly/Normal_Videos09...</td>\n",
       "      <td>Normal_Videos097_x264.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>Normal_Videos097_x264_i3d.npy</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/ubuntu/uca-virginia/Multimodal-Anomaly-D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>Training_Normal_Videos_Anomaly/Normal_Videos08...</td>\n",
       "      <td>Normal_Videos086_x264.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>Normal_Videos086_x264_i3d.npy</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/ubuntu/uca-virginia/Multimodal-Anomaly-D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  \\\n",
       "810  Training_Normal_Videos_Anomaly/Normal_Videos09...   \n",
       "811  Training_Normal_Videos_Anomaly/Normal_Videos08...   \n",
       "\n",
       "                         video  split                       npy_name  \\\n",
       "810  Normal_Videos097_x264.mp4  train  Normal_Videos097_x264_i3d.npy   \n",
       "811  Normal_Videos086_x264.mp4  train  Normal_Videos086_x264_i3d.npy   \n",
       "\n",
       "     is_normal                                          full_path  \n",
       "810       True  /home/ubuntu/uca-virginia/Multimodal-Anomaly-D...  \n",
       "811       True  /home/ubuntu/uca-virginia/Multimodal-Anomaly-D...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ucf[train_ucf['is_normal']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6c0f6213-6465-4586-a034-e285c83713dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ucf['full_path'] = train_base_dir + \"/\" + train_ucf['npy_name']\n",
    "\n",
    "output_file = \"../TEVAD/list/ucf-i3d.list\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for path in train_ucf['full_path']:\n",
    "        f.write(path + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6155fc58-8930-4389-8a94-56ae69dc5103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>video</th>\n",
       "      <th>split</th>\n",
       "      <th>npy_name</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>Training_Normal_Videos_Anomaly/Normal_Videos09...</td>\n",
       "      <td>Normal_Videos097_x264.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>Normal_Videos097_x264_i3d.npy</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/ubuntu/uca-virginia/Multimodal-Anomaly-D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>Training_Normal_Videos_Anomaly/Normal_Videos08...</td>\n",
       "      <td>Normal_Videos086_x264.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>Normal_Videos086_x264_i3d.npy</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/ubuntu/uca-virginia/Multimodal-Anomaly-D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  \\\n",
       "810  Training_Normal_Videos_Anomaly/Normal_Videos09...   \n",
       "811  Training_Normal_Videos_Anomaly/Normal_Videos08...   \n",
       "\n",
       "                         video  split                       npy_name  \\\n",
       "810  Normal_Videos097_x264.mp4  train  Normal_Videos097_x264_i3d.npy   \n",
       "811  Normal_Videos086_x264.mp4  train  Normal_Videos086_x264_i3d.npy   \n",
       "\n",
       "     is_normal                                          full_path  \n",
       "810       True  /home/ubuntu/uca-virginia/Multimodal-Anomaly-D...  \n",
       "811       True  /home/ubuntu/uca-virginia/Multimodal-Anomaly-D...  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ucf[train_ucf['is_normal']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c445b157-97d9-464b-86d2-cc47edb8e98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>video</th>\n",
       "      <th>split</th>\n",
       "      <th>npy_name</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>Training_Normal_Videos_Anomaly/Normal_Videos00...</td>\n",
       "      <td>Normal_Videos001_x264.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>Normal_Videos001_x264_i3d.npy</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/ubuntu/uca-virginia/Multimodal-Anomaly-D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  \\\n",
       "1310  Training_Normal_Videos_Anomaly/Normal_Videos00...   \n",
       "\n",
       "                          video  split                       npy_name  \\\n",
       "1310  Normal_Videos001_x264.mp4  train  Normal_Videos001_x264_i3d.npy   \n",
       "\n",
       "      is_normal                                          full_path  \n",
       "1310       True  /home/ubuntu/uca-virginia/Multimodal-Anomaly-D...  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ucf[train_ucf['npy_name']== 'Normal_Videos001_x264_i3d.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d698601b-4441-4fd2-a58e-bf309a36f11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_normal\n",
       "False    810\n",
       "True     800\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ucf['is_normal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "776d9ecc-6564-4a96-ac57-56a76172400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Sorting for Test\n",
    "test_ucf['npy_name'] = test_ucf['video'].str.replace('.mp4', '_i3d.npy')\n",
    "\n",
    "test_ucf['full_path'] = test_base_dir + \"/\" + test_ucf['npy_name']\n",
    "\n",
    "output_file = \"../TEVAD/list/ucf-i3d-test.list\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for path in train_df['full_path']:\n",
    "        f.write(path + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b467fa3c-5a61-4740-a78a-56fd3f358060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_normal\n",
       "False    206\n",
       "True     104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['is_normal'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce181e59-faf6-4684-a496-d684bcdac174",
   "metadata": {},
   "source": [
    "### TEVAD: Removing Extra Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c15592bc-ffbc-4023-91cd-5905503f6f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uca_split['emb_name'] = uca_split['video'].str.replace('.mp4', '_emb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0a7fbbd-71f4-4820-8371-fbab052430d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp= uca_split[['emb_name', 'split']].copy()\n",
    "temp.drop_duplicates(inplace = True)\n",
    "temp.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aaa8b244-ab31-4095-92de-93caf17e9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dir = \"../TEVAD/save/Crime/sent_emb_n\"\n",
    "\n",
    "expected = set(temp['emb_name'])\n",
    "actual = set(os.listdir(emb_dir))\n",
    "\n",
    "extra_files = actual-expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d8ce560-d3d2-44fa-974c-3e7443d42d77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in extra_files:\n",
    "    file_path = os.path.join(emb_dir, f)\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted: {f}\")\n",
    "    else:\n",
    "        print(f\"Skipped (not a file): {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d45f74-c555-4a68-b4b4-9fec33f71452",
   "metadata": {},
   "source": [
    "### TEVAD: Checking how Many Files are missing from Train/Test compared to UCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "91319133-a544-4129-88d0-13159bb475c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../../Anomaly_Train.txt\", sep = '/', header = None, names = ['folder', 'file'])\n",
    "test_df = pd.read_csv(\"../../Anomaly_Test.txt\", sep = '/', header = None, names = ['folder', 'file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "aee02134-28d1-40e4-8252-4a8a95e190ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abuse</td>\n",
       "      <td>Abuse001_x264.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abuse</td>\n",
       "      <td>Abuse002_x264.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  folder               file\n",
       "0  Abuse  Abuse001_x264.mp4\n",
       "1  Abuse  Abuse002_x264.mp4"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b4351562-b950-4858-acc4-dfefd19bac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['npy_name'] = train_df['file'].str.replace('.mp4', '_i3d.npy')\n",
    "test_df['npy_name'] = test_df['file'].str.replace('.mp4', '_i3d.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d0c30d6b-77ed-499c-a4d8-ed20be87a701",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = \"../TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Train_ten_crop_i3d\"\n",
    "test_img_dir = \"../TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Test_ten_crop_i3d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "86d26f61-5a78-421f-b92c-7c7b5bdbbc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>file</th>\n",
       "      <th>npy_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [folder, file, npy_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many missed files\n",
    "expected = set(train_df['npy_name'])\n",
    "actual = set(os.listdir(train_img_dir))\n",
    "missing_files = expected - actual\n",
    "\n",
    "train_rem = train_df[train_df['npy_name'].isin(missing_files)]\n",
    "train_rem\n",
    "#train_rem.to_csv(\"Train_Rem.csv\",index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3596f9b3-427c-468d-b66a-1b836fbc9b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5b935f07-bd9d-4f61-b56f-17d644ce3ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1610, 3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a3e407f7-9d7d-4607-a95c-e7943c18287f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>file</th>\n",
       "      <th>npy_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [folder, file, npy_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many missed files\n",
    "expected = set(test_df['npy_name'])\n",
    "actual = set(os.listdir(test_img_dir))\n",
    "missing_files = expected - actual\n",
    "\n",
    "test_rem = test_df[test_df['npy_name'].isin(missing_files)]\n",
    "test_rem\n",
    "#test_rem.to_csv(\"Test_Rem.csv\",index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "82381678-cbca-4c59-85f7-538b077b193e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6b134580-d4e9-4dbe-ba54-d3d1c2cd2a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290, 3)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a14cbc8b-50e9-4375-9056-a600f8910142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>file</th>\n",
       "      <th>npy_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abuse</td>\n",
       "      <td>Abuse001_x264.mp4</td>\n",
       "      <td>Abuse001_x264_i3d.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abuse</td>\n",
       "      <td>Abuse002_x264.mp4</td>\n",
       "      <td>Abuse002_x264_i3d.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abuse</td>\n",
       "      <td>Abuse003_x264.mp4</td>\n",
       "      <td>Abuse003_x264_i3d.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abuse</td>\n",
       "      <td>Abuse004_x264.mp4</td>\n",
       "      <td>Abuse004_x264_i3d.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abuse</td>\n",
       "      <td>Abuse005_x264.mp4</td>\n",
       "      <td>Abuse005_x264_i3d.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  folder               file               npy_name\n",
       "0  Abuse  Abuse001_x264.mp4  Abuse001_x264_i3d.npy\n",
       "1  Abuse  Abuse002_x264.mp4  Abuse002_x264_i3d.npy\n",
       "2  Abuse  Abuse003_x264.mp4  Abuse003_x264_i3d.npy\n",
       "3  Abuse  Abuse004_x264.mp4  Abuse004_x264_i3d.npy\n",
       "4  Abuse  Abuse005_x264.mp4  Abuse005_x264_i3d.npy"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "eaaab011-45b0-4162-9309-8dd2d7d7ebbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>file</th>\n",
       "      <th>npy_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [folder, file, npy_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['npy_name'] == 'Normal_Videos_781_x264_i3d.npy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2a034-b521-4adc-a9b8-0322d1c8f366",
   "metadata": {},
   "source": [
    "### LAVAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "737477c3-9d44-44af-a991-b6dcd1bd68ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lambda/nfs/uca-virginia/Multimodal-Anomaly-Detection-Survelliance-Videos/dataprep'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd3d45c5-6ba0-4f2c-bf64-2ed203b8d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- CONFIG ----\n",
    "TEMPORAL_ANNOT_FILE = \"../../original/Temporal_Anomaly_Annotation_for_Testing_Videos.txt\"\n",
    "VIDEO_ROOT = \"../../original\"\n",
    "PIPELINE_OUT = \"../../lavad/annotations/lavad_pipeline_annotations.txt\"\n",
    "GT_OUT_DIR = \"../../lavad/annotations/gt_masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b55051ab-001d-4ad2-8b6f-fb1dd4474701",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(GT_OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f90c87a4-bf88-414f-a72d-cb69bbaf02a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frames(video_path):\n",
    "    \"\"\"Count frames using OpenCV VideoCapture.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[ERROR] Cannot open: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return total\n",
    "\n",
    "\n",
    "def find_video_file(video_name):\n",
    "    \"\"\"\n",
    "    Recursively search VIDEO_ROOT for the file video_name + '.mp4'\n",
    "    Example: Abuse041_x264 -> Abuse041_x264.mp4\n",
    "    \"\"\"\n",
    "    target = video_name + \".mp4\"\n",
    "    for root, dirs, files in os.walk(VIDEO_ROOT):\n",
    "        if target in files:\n",
    "            return os.path.join(root, target)\n",
    "    print(f\"[WARN] Video file not found for: {video_name}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5c1e739-8349-4871-a27e-477964ea9286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Processed Abuse028_x264 (1412 frames)\n",
      "[OK] Processed Abuse030_x264 (1544 frames)\n",
      "[OK] Processed Arrest001_x264 (2374 frames)\n",
      "[OK] Processed Arrest007_x264 (3144 frames)\n",
      "[OK] Processed Arrest024_x264 (3629 frames)\n",
      "[OK] Processed Arrest030_x264 (8642 frames)\n",
      "[OK] Processed Arrest039_x264 (15835 frames)\n",
      "[OK] Processed Arson007_x264 (6252 frames)\n",
      "[OK] Processed Arson009_x264 (743 frames)\n",
      "[OK] Processed Arson010_x264 (3159 frames)\n",
      "[OK] Processed Arson011_x264 (1266 frames)\n",
      "[OK] Processed Arson016_x264 (1795 frames)\n",
      "[OK] Processed Arson018_x264 (842 frames)\n",
      "[OK] Processed Arson022_x264 (8640 frames)\n",
      "[OK] Processed Arson035_x264 (1437 frames)\n",
      "[OK] Processed Arson041_x264 (3754 frames)\n",
      "[OK] Processed Assault006_x264 (8096 frames)\n",
      "[OK] Processed Assault010_x264 (16177 frames)\n",
      "[OK] Processed Assault011_x264 (2288 frames)\n",
      "[OK] Processed Burglary005_x264 (7729 frames)\n",
      "[OK] Processed Burglary017_x264 (2113 frames)\n",
      "[OK] Processed Burglary018_x264 (1125 frames)\n",
      "[OK] Processed Burglary021_x264 (1537 frames)\n",
      "[OK] Processed Burglary024_x264 (3605 frames)\n",
      "[OK] Processed Burglary032_x264 (15795 frames)\n",
      "[OK] Processed Burglary033_x264 (1259 frames)\n",
      "[OK] Processed Burglary035_x264 (4050 frames)\n",
      "[OK] Processed Burglary037_x264 (1920 frames)\n",
      "[OK] Processed Burglary061_x264 (8990 frames)\n",
      "[OK] Processed Burglary076_x264 (12923 frames)\n",
      "[OK] Processed Burglary079_x264 (14853 frames)\n",
      "[OK] Processed Burglary092_x264 (625 frames)\n",
      "[OK] Processed Explosion002_x264 (4013 frames)\n",
      "[OK] Processed Explosion004_x264 (1902 frames)\n",
      "[OK] Processed Explosion007_x264 (16289 frames)\n",
      "[OK] Processed Explosion008_x264 (1748 frames)\n",
      "[OK] Processed Explosion010_x264 (2498 frames)\n",
      "[OK] Processed Explosion011_x264 (1571 frames)\n",
      "[OK] Processed Explosion013_x264 (3317 frames)\n",
      "[OK] Processed Explosion016_x264 (963 frames)\n",
      "[OK] Processed Explosion017_x264 (1643 frames)\n",
      "[OK] Processed Explosion020_x264 (1291 frames)\n",
      "[OK] Processed Explosion021_x264 (782 frames)\n",
      "[OK] Processed Explosion022_x264 (3594 frames)\n",
      "[OK] Processed Explosion025_x264 (505 frames)\n",
      "[OK] Processed Explosion027_x264 (776 frames)\n",
      "[OK] Processed Explosion028_x264 (1705 frames)\n",
      "[OK] Processed Explosion029_x264 (2410 frames)\n",
      "[OK] Processed Explosion033_x264 (3154 frames)\n",
      "[OK] Processed Explosion035_x264 (2865 frames)\n",
      "[OK] Processed Explosion036_x264 (5327 frames)\n",
      "[OK] Processed Explosion039_x264 (998 frames)\n",
      "[OK] Processed Explosion043_x264 (7646 frames)\n",
      "[OK] Processed Fighting003_x264 (3102 frames)\n",
      "[OK] Processed Fighting018_x264 (1389 frames)\n",
      "[OK] Processed Fighting033_x264 (1105 frames)\n",
      "[OK] Processed Fighting042_x264 (2237 frames)\n",
      "[OK] Processed Fighting047_x264 (4459 frames)\n",
      "[OK] Processed Normal_Videos_003_x264 (2822 frames)\n",
      "[OK] Processed Normal_Videos_006_x264 (450 frames)\n",
      "[OK] Processed Normal_Videos_010_x264 (1053 frames)\n",
      "[OK] Processed Normal_Videos_014_x264 (1499 frames)\n",
      "[OK] Processed Normal_Videos_015_x264 (480 frames)\n",
      "[OK] Processed Normal_Videos_018_x264 (1181 frames)\n",
      "[OK] Processed Normal_Videos_019_x264 (2843 frames)\n",
      "[OK] Processed Normal_Videos_024_x264 (1076 frames)\n",
      "[OK] Processed Normal_Videos_025_x264 (602 frames)\n",
      "[OK] Processed Normal_Videos_027_x264 (4922 frames)\n",
      "[OK] Processed Normal_Videos_033_x264 (1680 frames)\n",
      "[OK] Processed Normal_Videos_034_x264 (1318 frames)\n",
      "[OK] Processed Normal_Videos_041_x264 (1269 frames)\n",
      "[OK] Processed Normal_Videos_042_x264 (3154 frames)\n",
      "[OK] Processed Normal_Videos_048_x264 (1650 frames)\n",
      "[OK] Processed Normal_Videos_050_x264 (4198 frames)\n",
      "[OK] Processed Normal_Videos_051_x264 (2358 frames)\n",
      "[OK] Processed Normal_Videos_056_x264 (1572 frames)\n",
      "[OK] Processed Normal_Videos_059_x264 (1835 frames)\n",
      "[OK] Processed Normal_Videos_063_x264 (355 frames)\n",
      "[OK] Processed Normal_Videos_067_x264 (1068 frames)\n",
      "[OK] Processed Normal_Videos_070_x264 (993 frames)\n",
      "[OK] Processed Normal_Videos_100_x264 (627 frames)\n",
      "[OK] Processed Normal_Videos_129_x264 (467 frames)\n",
      "[OK] Processed Normal_Videos_150_x264 (864 frames)\n",
      "[OK] Processed Normal_Videos_168_x264 (1740 frames)\n",
      "[OK] Processed Normal_Videos_175_x264 (8847 frames)\n",
      "[OK] Processed Normal_Videos_182_x264 (4094 frames)\n",
      "[OK] Processed Normal_Videos_189_x264 (737 frames)\n",
      "[OK] Processed Normal_Videos_196_x264 (2004 frames)\n",
      "[OK] Processed Normal_Videos_203_x264 (2571 frames)\n",
      "[OK] Processed Normal_Videos_210_x264 (5408 frames)\n",
      "[OK] Processed Normal_Videos_217_x264 (1817 frames)\n",
      "[OK] Processed Normal_Videos_224_x264 (6958 frames)\n",
      "[OK] Processed Normal_Videos_246_x264 (4993 frames)\n",
      "[OK] Processed Normal_Videos_247_x264 (8211 frames)\n",
      "[OK] Processed Normal_Videos_248_x264 (1140 frames)\n",
      "[OK] Processed Normal_Videos_251_x264 (405 frames)\n",
      "[OK] Processed Normal_Videos_289_x264 (863 frames)\n",
      "[OK] Processed Normal_Videos_310_x264 (2518 frames)\n",
      "[OK] Processed Normal_Videos_312_x264 (1261 frames)\n",
      "[OK] Processed Normal_Videos_317_x264 (929 frames)\n",
      "[OK] Processed Normal_Videos_345_x264 (209 frames)\n",
      "[OK] Processed Normal_Videos_352_x264 (5403 frames)\n",
      "[OK] Processed Normal_Videos_360_x264 (984 frames)\n",
      "[OK] Processed Normal_Videos_365_x264 (6626 frames)\n",
      "[OK] Processed Normal_Videos_401_x264 (1626 frames)\n",
      "[OK] Processed Normal_Videos_417_x264 (1077 frames)\n",
      "[OK] Processed Normal_Videos_439_x264 (4226 frames)\n",
      "[OK] Processed Normal_Videos_452_x264 (443 frames)\n",
      "[OK] Processed Normal_Videos_453_x264 (5322 frames)\n",
      "[OK] Processed Normal_Videos_478_x264 (4502 frames)\n",
      "[OK] Processed Normal_Videos_576_x264 (11275 frames)\n",
      "[OK] Processed Normal_Videos_597_x264 (2229 frames)\n",
      "[OK] Processed Normal_Videos_603_x264 (3277 frames)\n",
      "[OK] Processed Normal_Videos_606_x264 (1233 frames)\n",
      "[OK] Processed Normal_Videos_621_x264 (4802 frames)\n",
      "[OK] Processed Normal_Videos_634_x264 (13459 frames)\n",
      "[OK] Processed Normal_Videos_641_x264 (3600 frames)\n",
      "[OK] Processed Normal_Videos_656_x264 (1815 frames)\n",
      "[OK] Processed Normal_Videos_686_x264 (2410 frames)\n",
      "[OK] Processed Normal_Videos_696_x264 (3625 frames)\n",
      "[OK] Processed Normal_Videos_702_x264 (2523 frames)\n",
      "[OK] Processed Normal_Videos_704_x264 (1694 frames)\n",
      "[OK] Processed Normal_Videos_710_x264 (1797 frames)\n",
      "[OK] Processed Normal_Videos_717_x264 (1255 frames)\n",
      "[OK] Processed Normal_Videos_722_x264 (8731 frames)\n",
      "[OK] Processed Normal_Videos_725_x264 (920 frames)\n",
      "[OK] Processed Normal_Videos_745_x264 (305 frames)\n",
      "[OK] Processed Normal_Videos_758_x264 (1589 frames)\n",
      "[OK] Processed Normal_Videos_778_x264 (1262 frames)\n",
      "[OK] Processed Normal_Videos_780_x264 (2021 frames)\n",
      "[OK] Processed Normal_Videos_781_x264 (3975 frames)\n",
      "[OK] Processed Normal_Videos_782_x264 (5543 frames)\n",
      "[OK] Processed Normal_Videos_783_x264 (9590 frames)\n",
      "[OK] Processed Normal_Videos_798_x264 (6001 frames)\n",
      "[OK] Processed Normal_Videos_801_x264 (2744 frames)\n",
      "[OK] Processed Normal_Videos_828_x264 (930 frames)\n",
      "[OK] Processed Normal_Videos_831_x264 (448 frames)\n",
      "[OK] Processed Normal_Videos_866_x264 (1198 frames)\n",
      "[OK] Processed Normal_Videos_867_x264 (624 frames)\n",
      "[OK] Processed Normal_Videos_868_x264 (2401 frames)\n",
      "[OK] Processed Normal_Videos_869_x264 (2401 frames)\n",
      "[OK] Processed Normal_Videos_870_x264 (601 frames)\n",
      "[OK] Processed Normal_Videos_871_x264 (4358 frames)\n",
      "[OK] Processed Normal_Videos_872_x264 (530 frames)\n",
      "[OK] Processed Normal_Videos_873_x264 (1799 frames)\n",
      "[OK] Processed Normal_Videos_874_x264 (4226 frames)\n",
      "[OK] Processed Normal_Videos_875_x264 (2565 frames)\n",
      "[OK] Processed Normal_Videos_876_x264 (351 frames)\n",
      "[OK] Processed Normal_Videos_877_x264 (10025 frames)\n",
      "[OK] Processed Normal_Videos_878_x264 (265 frames)\n",
      "[OK] Processed Normal_Videos_879_x264 (1143 frames)\n",
      "[OK] Processed Normal_Videos_880_x264 (18054 frames)\n",
      "[OK] Processed Normal_Videos_881_x264 (224 frames)\n",
      "[OK] Processed Normal_Videos_882_x264 (1654 frames)\n",
      "[OK] Processed Normal_Videos_883_x264 (326 frames)\n",
      "[OK] Processed Normal_Videos_884_x264 (9029 frames)\n",
      "[OK] Processed Normal_Videos_885_x264 (474 frames)\n",
      "[OK] Processed Normal_Videos_886_x264 (2747 frames)\n",
      "[OK] Processed Normal_Videos_887_x264 (7630 frames)\n",
      "[OK] Processed Normal_Videos_888_x264 (574 frames)\n",
      "[OK] Processed Normal_Videos_889_x264 (314 frames)\n",
      "[OK] Processed Normal_Videos_890_x264 (3579 frames)\n",
      "[OK] Processed Normal_Videos_891_x264 (1800 frames)\n",
      "[OK] Processed Normal_Videos_892_x264 (1770 frames)\n",
      "[OK] Processed Normal_Videos_893_x264 (6374 frames)\n",
      "[OK] Processed Normal_Videos_894_x264 (2575 frames)\n",
      "[OK] Processed Normal_Videos_895_x264 (3030 frames)\n",
      "[OK] Processed Normal_Videos_896_x264 (2303 frames)\n",
      "[OK] Processed Normal_Videos_897_x264 (875 frames)\n",
      "[OK] Processed Normal_Videos_898_x264 (1005 frames)\n",
      "[OK] Processed Normal_Videos_899_x264 (1380 frames)\n",
      "[OK] Processed Normal_Videos_900_x264 (1455 frames)\n",
      "[OK] Processed Normal_Videos_901_x264 (1170 frames)\n",
      "[OK] Processed Normal_Videos_902_x264 (1384 frames)\n",
      "[OK] Processed Normal_Videos_903_x264 (790 frames)\n",
      "[OK] Processed Normal_Videos_904_x264 (908 frames)\n",
      "[OK] Processed Normal_Videos_905_x264 (1196 frames)\n",
      "[OK] Processed Normal_Videos_906_x264 (676 frames)\n",
      "[OK] Processed Normal_Videos_907_x264 (598 frames)\n",
      "[OK] Processed Normal_Videos_908_x264 (889 frames)\n",
      "[OK] Processed Normal_Videos_909_x264 (870 frames)\n",
      "[OK] Processed Normal_Videos_910_x264 (567 frames)\n",
      "[OK] Processed Normal_Videos_911_x264 (776 frames)\n",
      "[OK] Processed Normal_Videos_912_x264 (746 frames)\n",
      "[OK] Processed Normal_Videos_913_x264 (609 frames)\n",
      "[OK] Processed Normal_Videos_914_x264 (880 frames)\n",
      "[OK] Processed Normal_Videos_915_x264 (1245 frames)\n",
      "[OK] Processed Normal_Videos_923_x264 (18224 frames)\n",
      "[OK] Processed Normal_Videos_924_x264 (107997 frames)\n",
      "[OK] Processed Normal_Videos_925_x264 (7726 frames)\n",
      "[OK] Processed Normal_Videos_926_x264 (1796 frames)\n",
      "[OK] Processed Normal_Videos_927_x264 (1633 frames)\n",
      "[OK] Processed Normal_Videos_928_x264 (918 frames)\n",
      "[OK] Processed Normal_Videos_929_x264 (924 frames)\n",
      "[OK] Processed Normal_Videos_930_x264 (3187 frames)\n",
      "[OK] Processed Normal_Videos_931_x264 (1765 frames)\n",
      "[OK] Processed Normal_Videos_932_x264 (1784 frames)\n",
      "[OK] Processed Normal_Videos_933_x264 (1771 frames)\n",
      "[OK] Processed Normal_Videos_934_x264 (1765 frames)\n",
      "[OK] Processed Normal_Videos_935_x264 (107994 frames)\n",
      "[OK] Processed Normal_Videos_936_x264 (1150 frames)\n",
      "[OK] Processed Normal_Videos_937_x264 (1150 frames)\n",
      "[OK] Processed Normal_Videos_938_x264 (4827 frames)\n",
      "[OK] Processed Normal_Videos_939_x264 (801 frames)\n",
      "[OK] Processed Normal_Videos_940_x264 (36017 frames)\n",
      "[OK] Processed Normal_Videos_941_x264 (2020 frames)\n",
      "[OK] Processed Normal_Videos_943_x264 (1020 frames)\n",
      "[OK] Processed Normal_Videos_944_x264 (7170 frames)\n",
      "[OK] Processed RoadAccidents001_x264 (1366 frames)\n",
      "[OK] Processed RoadAccidents002_x264 (347 frames)\n",
      "[OK] Processed RoadAccidents004_x264 (389 frames)\n",
      "[OK] Processed RoadAccidents009_x264 (918 frames)\n",
      "[OK] Processed RoadAccidents010_x264 (528 frames)\n",
      "[OK] Processed RoadAccidents011_x264 (2159 frames)\n",
      "[OK] Processed RoadAccidents012_x264 (468 frames)\n",
      "[OK] Processed RoadAccidents016_x264 (2192 frames)\n",
      "[OK] Processed RoadAccidents017_x264 (243 frames)\n",
      "[OK] Processed RoadAccidents019_x264 (1314 frames)\n",
      "[OK] Processed RoadAccidents020_x264 (1773 frames)\n",
      "[OK] Processed RoadAccidents021_x264 (155 frames)\n",
      "[OK] Processed RoadAccidents022_x264 (716 frames)\n",
      "[OK] Processed RoadAccidents121_x264 (1835 frames)\n",
      "[OK] Processed RoadAccidents122_x264 (647 frames)\n",
      "[OK] Processed RoadAccidents123_x264 (1005 frames)\n",
      "[OK] Processed RoadAccidents124_x264 (1495 frames)\n",
      "[OK] Processed RoadAccidents125_x264 (1771 frames)\n",
      "[OK] Processed RoadAccidents127_x264 (2580 frames)\n",
      "[OK] Processed RoadAccidents128_x264 (565 frames)\n",
      "[OK] Processed RoadAccidents131_x264 (1524 frames)\n",
      "[OK] Processed RoadAccidents132_x264 (1862 frames)\n",
      "[OK] Processed RoadAccidents133_x264 (673 frames)\n",
      "[OK] Processed Robbery048_x264 (1409 frames)\n",
      "[OK] Processed Robbery050_x264 (1701 frames)\n",
      "[OK] Processed Robbery102_x264 (1827 frames)\n",
      "[OK] Processed Robbery106_x264 (1197 frames)\n",
      "[OK] Processed Robbery137_x264 (2193 frames)\n",
      "[OK] Processed Shooting002_x264 (1206 frames)\n",
      "[OK] Processed Shooting004_x264 (1793 frames)\n",
      "[OK] Processed Shooting007_x264 (1430 frames)\n",
      "[OK] Processed Shooting008_x264 (1625 frames)\n",
      "[OK] Processed Shooting010_x264 (2641 frames)\n",
      "[OK] Processed Shooting011_x264 (4003 frames)\n",
      "[OK] Processed Shooting013_x264 (1073 frames)\n",
      "[OK] Processed Shooting015_x264 (1713 frames)\n",
      "[OK] Processed Shooting018_x264 (1799 frames)\n",
      "[OK] Processed Shooting019_x264 (2756 frames)\n",
      "[OK] Processed Shooting021_x264 (1275 frames)\n",
      "[OK] Processed Shooting022_x264 (4554 frames)\n",
      "[OK] Processed Shooting024_x264 (2003 frames)\n",
      "[OK] Processed Shooting026_x264 (1403 frames)\n",
      "[OK] Processed Shooting028_x264 (1898 frames)\n",
      "[OK] Processed Shooting032_x264 (21681 frames)\n",
      "[OK] Processed Shooting033_x264 (3630 frames)\n",
      "[OK] Processed Shooting034_x264 (1409 frames)\n",
      "[OK] Processed Shooting037_x264 (305 frames)\n",
      "[OK] Processed Shooting043_x264 (1874 frames)\n",
      "[OK] Processed Shooting046_x264 (5088 frames)\n",
      "[OK] Processed Shooting047_x264 (8287 frames)\n",
      "[OK] Processed Shooting048_x264 (2741 frames)\n",
      "[OK] Processed Shoplifting001_x264 (4344 frames)\n",
      "[OK] Processed Shoplifting004_x264 (6673 frames)\n",
      "[OK] Processed Shoplifting005_x264 (1967 frames)\n",
      "[OK] Processed Shoplifting007_x264 (5124 frames)\n",
      "[OK] Processed Shoplifting010_x264 (2736 frames)\n",
      "[OK] Processed Shoplifting015_x264 (2256 frames)\n",
      "[OK] Processed Shoplifting016_x264 (1483 frames)\n",
      "[OK] Processed Shoplifting017_x264 (457 frames)\n",
      "[OK] Processed Shoplifting020_x264 (5770 frames)\n",
      "[OK] Processed Shoplifting021_x264 (3551 frames)\n",
      "[OK] Processed Shoplifting022_x264 (2191 frames)\n",
      "[OK] Processed Shoplifting027_x264 (1873 frames)\n",
      "[OK] Processed Shoplifting028_x264 (1357 frames)\n",
      "[OK] Processed Shoplifting029_x264 (2176 frames)\n",
      "[OK] Processed Shoplifting031_x264 (447 frames)\n",
      "[OK] Processed Shoplifting033_x264 (899 frames)\n",
      "[OK] Processed Shoplifting034_x264 (11937 frames)\n",
      "[OK] Processed Shoplifting037_x264 (1386 frames)\n",
      "[OK] Processed Shoplifting039_x264 (2803 frames)\n",
      "[OK] Processed Shoplifting044_x264 (14555 frames)\n",
      "[OK] Processed Shoplifting049_x264 (2149 frames)\n",
      "[OK] Processed Stealing019_x264 (4911 frames)\n",
      "[OK] Processed Stealing036_x264 (2503 frames)\n",
      "[OK] Processed Stealing058_x264 (4991 frames)\n",
      "[OK] Processed Stealing062_x264 (1560 frames)\n",
      "[OK] Processed Stealing079_x264 (5846 frames)\n",
      "[OK] Processed Vandalism007_x264 (1146 frames)\n",
      "[OK] Processed Vandalism015_x264 (2982 frames)\n",
      "[OK] Processed Vandalism017_x264 (1011 frames)\n",
      "[OK] Processed Vandalism028_x264 (4495 frames)\n",
      "[OK] Processed Vandalism036_x264 (1443 frames)\n",
      "\n",
      "DONE!\n",
      "Pipeline annotation saved to: ../../lavad/annotations/lavad_pipeline_annotations.txt\n",
      "GT masks saved in: ../../lavad/annotations/gt_masks\n"
     ]
    }
   ],
   "source": [
    "pipeline_lines = []\n",
    "\n",
    "with open(TEMPORAL_ANNOT_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "\n",
    "        parts = line.split()\n",
    "        video_mp4 = parts[0]                # e.g., Abuse041_x264.mp4\n",
    "        video_name = video_mp4.replace(\".mp4\", \"\")\n",
    "\n",
    "        s1, e1 = int(parts[2]), int(parts[3])\n",
    "        s2, e2 = int(parts[4]), int(parts[5])\n",
    "\n",
    "        # Label: 1 if abnormal, 0 if normal\n",
    "        label = 0 if s1 == -1 else 1\n",
    "\n",
    "        # Find video on disk\n",
    "        video_path = find_video_file(video_name)\n",
    "        if video_path is None:\n",
    "            continue\n",
    "\n",
    "        # Count frames\n",
    "        num_frames = count_frames(video_path)\n",
    "        if num_frames is None:\n",
    "            continue\n",
    "\n",
    "        start_frame = 0\n",
    "        end_frame = num_frames - 1\n",
    "\n",
    "        # Save pipeline annotation line\n",
    "        pipeline_lines.append(f\"{video_name} {start_frame} {end_frame} {label}\")\n",
    "\n",
    "        # ----------------------------\n",
    "        # GENERATE FRAME-LEVEL GT MASK\n",
    "        # ----------------------------\n",
    "        gt = np.zeros(num_frames, dtype=np.int32)\n",
    "\n",
    "        if label == 1:\n",
    "            if s1 != -1:\n",
    "                gt[s1:e1+1] = 1\n",
    "            if s2 != -1:\n",
    "                gt[s2:e2+1] = 1\n",
    "\n",
    "        np.save(os.path.join(GT_OUT_DIR, f\"{video_name}.npy\"), gt)\n",
    "        print(f\"[OK] Processed {video_name} ({num_frames} frames)\")\n",
    "\n",
    "# Save pipeline file\n",
    "with open(PIPELINE_OUT, \"w\") as f:\n",
    "    f.write(\"\\n\".join(pipeline_lines))\n",
    "\n",
    "print(\"\\nDONE!\")\n",
    "print(f\"Pipeline annotation saved to: {PIPELINE_OUT}\")\n",
    "print(f\"GT masks saved in: {GT_OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8072283-5e6c-423f-84ac-66c0000bc13d",
   "metadata": {},
   "source": [
    "### Creating Final Test For Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d6175368-0d16-437f-80e9-01463379e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../../Anomaly_Test.txt\", sep = '/', header = None, names = ['folder', 'file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "db03e089-43d6-4c7f-95c4-1ef95e6f5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_root = \"/lambda/nfs/uca-virginia/original\"      \n",
    "dst_root = \"/lambda/nfs/uca-virginia/test_videos_raw\" \n",
    "\n",
    "os.makedirs(dst_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1a9bd329-8293-4722-90c9-c2bb1573786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['folder'] = test_df['folder'].str.replace(\"Testing_Normal_Videos_Anomaly\", \"Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "32ea4aa0-e572-4cca-942b-f934b323defd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal_Videos_003_x264.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     folder                        file\n",
       "135  Normal  Normal_Videos_003_x264.mp4"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['file'] == 'Normal_Videos_003_x264.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ae6f2906-9406-4d07-b4ad-3e38d3d63a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying videos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 290/290 [01:22<00:00,  3.50it/s]\n"
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Copying videos\"):\n",
    "    folder = row[\"folder\"]\n",
    "    filename = row[\"file\"]\n",
    "\n",
    "    src_path = os.path.join(src_root, folder, filename)\n",
    "    dst_path = os.path.join(dst_root, filename)\n",
    "\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    else:\n",
    "        print(f\"Missing: {src_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8658953d-30bd-4d12-833d-dfa6fadce466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEVAD Env",
   "language": "python",
   "name": "tev_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
