{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb6160cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from moviepy import VideoFileClip\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15721a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Prep Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "429fb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize dataset structure\n",
    "def summarize_dataset_structure(base_dir=\".\"):\n",
    "    \"\"\"\n",
    "    Summarize how many videos exist in each class folder across train/val/test splits.\n",
    "    Handles nested folder structures (e.g., class -> video -> clips).\n",
    "\n",
    "    Example layout:\n",
    "        base_dir/\n",
    "            train/\n",
    "                Abuse/\n",
    "                    Abuse001_x264/\n",
    "                        Abuse001_x264_0.mp4\n",
    "                        Abuse001_x264_1.mp4\n",
    "                Shoplifting/\n",
    "            val/\n",
    "            test/\n",
    "    \"\"\"\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        split_path = os.path.join(base_dir, split)\n",
    "        if not os.path.exists(split_path):\n",
    "            print(f\"‚ö†Ô∏è Split folder not found: {split_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nüìÇ Stats for split: {split}\")\n",
    "        total_videos = 0\n",
    "\n",
    "        # Iterate over each class folder (Abuse, Shoplifting, etc.)\n",
    "        for cls in sorted(os.listdir(split_path)):\n",
    "            cls_path = os.path.join(split_path, cls)\n",
    "            if not os.path.isdir(cls_path):\n",
    "                continue\n",
    "\n",
    "            video_count = 0\n",
    "\n",
    "            # Go into subdirectories (e.g., Abuse001_x264)\n",
    "            for root, _, files in os.walk(cls_path):\n",
    "                video_files = [\n",
    "                    f for f in files\n",
    "                    if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.npy'))\n",
    "                ]\n",
    "                video_count += len(video_files)\n",
    "\n",
    "            print(f\"  üóÇÔ∏è {cls}: {video_count} video clips\")\n",
    "            total_videos += video_count\n",
    "\n",
    "        print(f\"  ‚û§ Total video clips in '{split}': {total_videos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d4a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load UCF Crime-style JSON annotations\n",
    "def load_ucf_json(json_path):\n",
    "    \"\"\"\n",
    "    Loads a UCF Crime-style JSON annotation file and converts it\n",
    "    into a flattened pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        json_path (str): Path to the JSON annotation file.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Flattened DataFrame with columns:\n",
    "            ['video', 'duration', 'start', 'end', 'description']\n",
    "    \"\"\"\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    rows = []\n",
    "    for video, info in data.items():\n",
    "        for (ts, sentence) in zip(info.get(\"timestamps\", []), info.get(\"sentences\", [])):\n",
    "            rows.append({\n",
    "                \"video\": video,\n",
    "                \"duration\": info.get(\"duration\", None),\n",
    "                \"start\": ts[0],\n",
    "                \"end\": ts[1],\n",
    "                \"description\": sentence\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb4d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_clip_paths(df):\n",
    "    \"\"\"\n",
    "    Adds a 'clip_path' column based only on DataFrame columns:\n",
    "    folder/video_basename/video_basename_i.mp4\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): must contain 'folder' and 'video' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: with an extra column 'clip_path'\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Remove .mp4 extension from video to get folder/video base\n",
    "    df[\"video_base\"] = df[\"video\"].str.replace(\".mp4\", \"\", regex=False)\n",
    "\n",
    "    # Get index per unique (folder, video) group ‚Äî i = 0, 1, 2, ...\n",
    "    df[\"clip_idx\"] = df.groupby([\"folder\", \"video\"]).cumcount()\n",
    "\n",
    "    # Construct the relative path\n",
    "    df[\"clip_path\"] = df.apply(\n",
    "        lambda row: f\"{row['folder']}/{row['video_base']}/{row['video_base']}_{row['clip_idx']}.mp4\",\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df.drop(['video_base', 'clip_idx'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c074cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Loading UCA Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2498a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../Surveillance-Video-Understanding-main/ucf-annotation/json/UCFCrime_Train.json\"\n",
    "test_file = \"../Surveillance-Video-Understanding-main/ucf-annotation/json/UCFCrime_Test.json\"\n",
    "val_file = \"../Surveillance-Video-Understanding-main/ucf-annotation/json/UCFCrime_Val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_ucf_json(train_file)\n",
    "test_df = load_ucf_json(test_file)\n",
    "val_df = load_ucf_json(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['folder'] = train_df['video'].apply(lambda x: re.match(r'([A-Za-z]+)', x).group(1) if re.match(r'([A-Za-z]+)', x) else None)\n",
    "test_df['folder'] = test_df['video'].apply(lambda x: re.match(r'([A-Za-z]+)', x).group(1) if re.match(r'([A-Za-z]+)', x) else None)\n",
    "val_df['folder'] = val_df['video'].apply(lambda x: re.match(r'([A-Za-z]+)', x).group(1) if re.match(r'([A-Za-z]+)', x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6479a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['video'] = train_df['video']+\".mp4\"\n",
    "test_df['video'] = test_df['video']+\".mp4\"\n",
    "val_df['video'] = val_df['video']+\".mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffde7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = add_clip_paths(train_df)\n",
    "train_df[train_df[\"video\"] == \"Abuse001_x264.mp4\"][[\"folder\", \"video\", \"clip_path\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8eef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = add_clip_paths(test_df)\n",
    "val_df = add_clip_paths(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b457912",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['split'] = 'train'\n",
    "test_df['split'] = 'test'\n",
    "val_df['split'] = 'val'\n",
    "\n",
    "all_annotations = pd.concat([train_df, test_df, val_df], ignore_index=True)\n",
    "\n",
    "# Expringting all annotations to CSV\n",
    "all_annotations.to_csv(\"../uca-dataset/uca_annotations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16559454",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Preparing UCA Dataset with Clipped Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_videos_from_df(df, source_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Clips videos using MoviePy 2.x API based on 'start' and 'end' times in the DataFrame.\n",
    "    Displays a progress bar and only logs failures or invalid clips.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    total_videos = df['video'].nunique()\n",
    "\n",
    "    print(f\"üé¨ Starting video clipping for {total_videos} unique videos ({len(df)} total clips)...\\n\")\n",
    "\n",
    "    # Group videos first\n",
    "    grouped_videos = list(df.groupby([\"folder\", \"video\"]))\n",
    "\n",
    "    # tqdm progress bar\n",
    "    for (folder, video_name), group in tqdm(grouped_videos, desc=\"Processing videos\", unit=\"video\"):\n",
    "        src_path = os.path.join(source_dir, folder, video_name)\n",
    "        base_name, ext = os.path.splitext(video_name)\n",
    "        dest_subdir = os.path.join(output_dir, folder, base_name)\n",
    "        os.makedirs(dest_subdir, exist_ok=True)\n",
    "\n",
    "        if not os.path.exists(src_path):\n",
    "            print(f\"‚ö†Ô∏è Missing source video: {src_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            video = VideoFileClip(src_path)\n",
    "            for i, row in enumerate(group.itertuples(index=False)):\n",
    "                start = float(row.start)\n",
    "                end = min(float(row.end), video.duration)\n",
    "\n",
    "                # Skip invalid segments\n",
    "                if end <= start:\n",
    "                    print(f\"‚è© Skipping invalid segment ({start:.2f}-{end:.2f}) in {video_name}\")\n",
    "                    continue\n",
    "\n",
    "                clip = video.subclipped(start, end)\n",
    "                dest_path = os.path.join(dest_subdir, f\"{base_name}_{i}.mp4\")\n",
    "\n",
    "                # Silent writing (no MoviePy output spam)\n",
    "                clip.write_videofile(dest_path, audio=False, logger=None)\n",
    "\n",
    "            video.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {src_path}: {e}\")\n",
    "\n",
    "    print(\"\\n‚úÖ All videos processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec59f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_dir = '../original-ucf/Videos'\n",
    "destination_dir = '../uca-dataset'\n",
    "\n",
    "clip_videos_from_df(\n",
    "    df=train_df,\n",
    "    source_dir=source_dir,         \n",
    "    output_dir=destination_dir+\"/train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c3436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_dir = '../original-ucf/Videos'\n",
    "destination_dir = '../uca-dataset'\n",
    "\n",
    "clip_videos_from_df(\n",
    "    df=val_df,\n",
    "    source_dir=source_dir,         \n",
    "    output_dir=destination_dir+\"/val\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f824f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_dir = '../original-ucf/Videos'\n",
    "destination_dir = '../uca-dataset'\n",
    "\n",
    "clip_videos_from_df(\n",
    "    df=test_df,\n",
    "    source_dir=source_dir,         \n",
    "    output_dir=destination_dir+\"/test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f95ba1",
   "metadata": {},
   "source": [
    "#### Validating Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca009964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_duplicates(df, subset_cols=[\"video\", \"start\", \"end\", \"description\"]):\n",
    "    \"\"\"\n",
    "    Checks for duplicate video segments based on selected columns.\n",
    "    Prints how many duplicates exist and which videos have them.\n",
    "    \"\"\"\n",
    "    duplicated_rows = df[df.duplicated(subset=subset_cols, keep=False)]\n",
    "    total_dupes = len(duplicated_rows)\n",
    "\n",
    "    if total_dupes == 0:\n",
    "        print(\"‚úÖ No duplicates found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìä Found {total_dupes} duplicate rows based on {subset_cols}\")\n",
    "\n",
    "    # Count duplicates per video\n",
    "    dupe_counts = (\n",
    "        duplicated_rows.groupby([\"video\", \"start\", \"end\"])\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index(name=\"duplicate_count\")\n",
    "    )\n",
    "\n",
    "    print(\"\\nüéûÔ∏è Videos with duplicate timestamps:\")\n",
    "    display(dupe_counts.head(10))  # show top 10 by default\n",
    "\n",
    "    return duplicated_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_duplicates(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ead174",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_duplicates(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32dc3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_rows = check_for_duplicates(train_df)\n",
    "# These duplicates are present in th original transcripts as well. Leaving them for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93560002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This aligns perfectly with the UCA paper table 3\n",
    "destination_dir = \"../uca-dataset\"\n",
    "summarize_dataset_structure(base_dir=destination_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28387a3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### YAML File Creation - Fine Tune SwinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yaml_files(df, output_dir=\"../UCA-Dataset/w-captions/\"):\n",
    "    \"\"\"\n",
    "    Converts UCA annotations CSV into SwinBERT-compatible YAML files for train/val/test.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to CSV file with columns ['clip_path', 'description', 'split'].\n",
    "        output_dir (str): Folder where YAMLs will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Validate required columns\n",
    "    required = {\"clip_path\", \"description\", \"split\"}\n",
    "    if not required.issubset(df.columns):\n",
    "        raise ValueError(f\"CSV must contain columns: {required}\")\n",
    "\n",
    "    # Generate YAML for each split\n",
    "    for split in df[\"split\"].unique():\n",
    "        split_df = df[df[\"split\"] == split]\n",
    "        split_yaml = {\n",
    "            # This is based on file structure in Cloud GPU Instance\n",
    "            f\"{split}_videos\": [os.path.join(\"../UCA-Dataset/w-captions\", p) for p in split_df[\"clip_path\"]],\n",
    "            \"captions\": split_df[\"description\"].tolist()\n",
    "        }\n",
    "\n",
    "        out_path = os.path.join(output_dir, f\"{split}.yaml\")\n",
    "        with open(out_path, \"w\") as f:\n",
    "            yaml.dump(split_yaml, f, default_flow_style=False, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "        print(f\"‚úÖ Saved: {out_path} ({len(split_df)} entries)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99061546",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations = pd.read_csv(\"../UCA-Dataset/uca_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e64d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations['description'] = all_annotations['description'].str.replace('\\n', ' ').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yaml_files(all_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162584dc-68cf-4885-8d34-d99fe266b6d1",
   "metadata": {},
   "source": [
    "### Aligning TEVAD data based on UCF to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4480e8b0-1416-4dc9-a48d-aa62b176efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "uca_split = pd.read_csv(\"../../uca_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96d7378a-1473-46a3-91bc-d8b4fbd2ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uca = uca_split[(uca_split['split'] =='train') | (uca_split['split'] == 'val')]['video'].unique()\n",
    "test_uca = uca_split[(uca_split['split'] !='train') & (uca_split['split'] != 'val')]['video'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bab5b5ee-7656-42bb-aa86-55d1f6ae624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original UCF\n",
    "train_ucf = pd.read_csv(\"../../Anomaly_Train_org.txt\", header=None,\n",
    "    names=[\"path\"])\n",
    "\n",
    "train_ucf['video'] = train_ucf['path'].str.split('/').str[1]\n",
    "\n",
    "test_ucf = pd.read_csv(\"../../Anomaly_Test_org.txt\", header=None,\n",
    "    names=[\"path\"])\n",
    "\n",
    "test_ucf['video'] = test_ucf['path'].str.split('/').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46201301-d1e4-4dcd-928d-908ff40cb081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_uca).difference(set(train_ucf['video'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1efa491-16b6-4fd3-b8f3-eb8e7f63787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uca_split['npy_name'] = uca_split['video'].str.replace('.mp4', '_i3d.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0035d805-d187-4e0e-a028-5da62d70ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 moving all files to all central location\n",
    "src_dir = \"../TEVAD/save/Crime/UCF_ten_crop_i3d_v1\"\n",
    "dest_dir = \"../TEVAD/save/Crime/UCF_all_i3d\"\n",
    "\n",
    "subfolders = [\"UCF_Train_ten_crop_i3d\", \"UCF_Test_ten_crop_i3d\"]\n",
    "\n",
    "for sub in subfolders:\n",
    "    sub_path = os.path.join(src_dir, sub)\n",
    "    \n",
    "    for file in os.listdir(sub_path):\n",
    "        src_path = os.path.join(sub_path, file)\n",
    "        dst_path = os.path.join(dest_dir, file)\n",
    "\n",
    "        if os.path.isfile(src_path):\n",
    "            shutil.move(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a05355ee-c600-4676-b1db-29b70fe6507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = \"../TEVAD/save/Crime/UCF_all_i3d\"\n",
    "train_dir = \"../TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Train_ten_crop_i3d\"\n",
    "test_dir = \"../TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Test_ten_crop_i3d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fb9be02-21ff-46c9-a4aa-5f08a0598e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = uca_split[['npy_name', 'split']].copy()\n",
    "df.drop_duplicates(inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10a5ead3-8f53-4cf4-a608-ee8ef5cf07d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1854, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f39f1fa5-21ee-421f-adf1-729d2089f8d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    filename = row['npy_name']\n",
    "    split = row['split']\n",
    "\n",
    "    src_path = os.path.join(src_dir, filename)\n",
    "\n",
    "    # Determine destination\n",
    "    if split in ['train', 'val']:\n",
    "        dst_path = os.path.join(train_dir, filename)\n",
    "    else:  # test\n",
    "        dst_path = os.path.join(test_dir, filename)\n",
    "\n",
    "    # Move if exists\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.move(src_path, dst_path)\n",
    "    else:\n",
    "        print(f\"Missing file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ffa53ce-77dd-47a4-a6ae-9b5de642e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dest_dir = \"../TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Train_ten_crop_i3d\"\n",
    "test_dest_dir = \"../TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Test_ten_crop_i3d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bec1d12c-2153-4d0b-8cd8-8ff5ae7f446c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npy_name</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [npy_name, split]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if we missed any files\n",
    "train_df = uca_split[['npy_name', 'split']][(uca_split['split'] =='train') | (uca_split['split'] == 'val')].copy()\n",
    "train_df.drop_duplicates(inplace = True)\n",
    "train_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "expected = set(train_df['npy_name'])\n",
    "actual = set(os.listdir(train_dest_dir))\n",
    "missing_files = expected - actual\n",
    "\n",
    "train_rem = train_df[train_df['npy_name'].isin(missing_files)]\n",
    "train_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c5b0aa7-63ba-4911-9202-16ff28457c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npy_name</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [npy_name, split]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = uca_split[['npy_name', 'split']][(uca_split['split'] =='test')].copy()\n",
    "test_df.drop_duplicates(inplace = True)\n",
    "test_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "expected = set(test_df['npy_name'])\n",
    "actual = set(os.listdir(test_dest_dir))\n",
    "missing_files = expected - actual\n",
    "\n",
    "test_rem = test_df[test_df['npy_name'].isin(missing_files)]\n",
    "test_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9219ab35-f68c-47ac-89bb-bda6a9d237d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above missing files due to redundancies in uca-split (annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65179784-c413-4dfd-b2f4-4d11c165bfd2",
   "metadata": {},
   "source": [
    "### Creating Train/Test List and Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3638f6b1-7be8-4d1b-92de-84a8cd553e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_dir = \"../TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Train_ten_crop_i3d\"\n",
    "test_base_dir = \"../TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Test_ten_crop_i3d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c0f6213-6465-4586-a034-e285c83713dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_normal'] = train_df['npy_name'].str.startswith(\"Normal_Videos\")\n",
    "\n",
    "train_df = train_df.sort_values(by='is_normal', ascending=True)\n",
    "train_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "train_df['full_path'] = train_base_dir + \"/\" + train_df['npy_name']\n",
    "\n",
    "output_file = \"../TEVAD/list/ucf-i3d.list\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for path in train_df['full_path']:\n",
    "        f.write(path + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c445b157-97d9-464b-86d2-cc47edb8e98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npy_name</th>\n",
       "      <th>split</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Shoplifting048_x264_i3d.npy</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>../TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        npy_name split  is_normal  \\\n",
       "355  Shoplifting048_x264_i3d.npy   val      False   \n",
       "\n",
       "                                             full_path  \n",
       "355  ../TEVAD/save/Crime/UCF_ten_crop_i3d_v1/UCF_Tr...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['npy_name']== 'Shoplifting048_x264_i3d.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d698601b-4441-4fd2-a58e-bf309a36f11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_normal\n",
       "True     806\n",
       "False    738\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['is_normal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "776d9ecc-6564-4a96-ac57-56a76172400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['is_normal'] = test_df['npy_name'].str.startswith(\"Normal_Videos\")\n",
    "\n",
    "test_df = test_df.sort_values(by='is_normal', ascending=True)\n",
    "test_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "test_df['full_path'] = test_base_dir + \"/\" + test_df['npy_name']\n",
    "\n",
    "output_file = \"../TEVAD/list/ucf-i3d-test.list\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for path in train_df['full_path']:\n",
    "        f.write(path + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b467fa3c-5a61-4740-a78a-56fd3f358060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_normal\n",
       "False    206\n",
       "True     104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['is_normal'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce181e59-faf6-4684-a496-d684bcdac174",
   "metadata": {},
   "source": [
    "### Removing Extra Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c15592bc-ffbc-4023-91cd-5905503f6f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uca_split['emb_name'] = uca_split['video'].str.replace('.mp4', '_emb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0a7fbbd-71f4-4820-8371-fbab052430d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp= uca_split[['emb_name', 'split']].copy()\n",
    "temp.drop_duplicates(inplace = True)\n",
    "temp.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aaa8b244-ab31-4095-92de-93caf17e9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dir = \"../TEVAD/save/Crime/sent_emb_n\"\n",
    "\n",
    "expected = set(temp['emb_name'])\n",
    "actual = set(os.listdir(emb_dir))\n",
    "\n",
    "extra_files = actual-expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d8ce560-d3d2-44fa-974c-3e7443d42d77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in extra_files:\n",
    "    file_path = os.path.join(emb_dir, f)\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted: {f}\")\n",
    "    else:\n",
    "        print(f\"Skipped (not a file): {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe33c98-9bde-4419-bf56-73715ecaa3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEVAD Env",
   "language": "python",
   "name": "tev_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
