11/16/2025 17:21:09 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 17:21:09 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 17:21:09 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 17:21:09 - INFO - __main__ -   video swin (config path): /home/ubuntu/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 17:21:09 - INFO - __main__ -   video swin (model path): /home/ubuntu/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 17:24:16 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 17:24:16 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 17:24:16 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 17:24:16 - INFO - __main__ -   video swin (config path): /home/ubuntu/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 17:24:16 - INFO - __main__ -   video swin (model path): /home/ubuntu/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 17:24:18 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 17:24:21 - INFO - __main__ -   Init model from scratch.
11/16/2025 17:24:21 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 17:24:21 - INFO - __main__ -   yaml_file:./w-captions/train.yaml
11/16/2025 17:26:09 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 17:26:09 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 17:26:09 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 17:26:09 - INFO - __main__ -   video swin (config path): /home/ubuntu/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 17:26:09 - INFO - __main__ -   video swin (model path): /home/ubuntu/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 17:26:10 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 17:26:14 - INFO - __main__ -   Init model from scratch.
11/16/2025 17:26:14 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 17:26:14 - INFO - __main__ -   yaml_file:../UCA-Dataset/w-captions/train.yaml
11/16/2025 17:27:01 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 17:27:01 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 17:27:01 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 17:27:01 - INFO - __main__ -   video swin (config path): /home/ubuntu/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 17:27:01 - INFO - __main__ -   video swin (model path): /home/ubuntu/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 17:27:03 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 17:27:06 - INFO - __main__ -   Init model from scratch.
11/16/2025 17:27:06 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 17:27:06 - INFO - __main__ -   yaml_file:../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:11:28 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 19:11:28 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 19:11:28 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 19:11:28 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 19:11:28 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 19:11:30 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 19:11:33 - INFO - __main__ -   Init model from scratch.
11/16/2025 19:11:33 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 19:11:34 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:11:39 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:11:39 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 19:11:39 - INFO - __main__ -   Total batch size 1
11/16/2025 19:11:39 - INFO - __main__ -   Total training steps 156770
11/16/2025 19:11:39 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:18:17 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 19:18:17 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 19:18:17 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 19:18:17 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 19:18:17 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 19:18:19 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 19:18:23 - INFO - __main__ -   Init model from scratch.
11/16/2025 19:18:23 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 19:18:23 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:18:29 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:18:29 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 19:18:29 - INFO - __main__ -   Total batch size 1
11/16/2025 19:18:29 - INFO - __main__ -   Total training steps 156770
11/16/2025 19:18:29 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:23:39 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 19:23:39 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 19:23:39 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 19:23:39 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 19:23:39 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 19:23:40 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 19:23:44 - INFO - __main__ -   Init model from scratch.
11/16/2025 19:23:44 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 19:23:44 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:23:50 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:23:50 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 19:23:50 - INFO - __main__ -   Total batch size 1
11/16/2025 19:23:50 - INFO - __main__ -   Total training steps 156770
11/16/2025 19:23:50 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:23:51 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:29:04 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 19:29:04 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 19:29:04 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 19:29:04 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 19:29:04 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 19:29:05 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 19:29:08 - INFO - __main__ -   Init model from scratch.
11/16/2025 19:29:08 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 19:29:08 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:29:13 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:29:13 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 19:29:13 - INFO - __main__ -   Total batch size 1
11/16/2025 19:29:13 - INFO - __main__ -   Total training steps 156770
11/16/2025 19:29:13 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:29:14 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:29:14 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 19:29:14 - INFO - __main__ -   Training/evaluation parameters: {'data_dir': 'datasets', 'output_dir': './models/table1/uca_finetune/', 'train_yaml': '../UCA-Dataset/w-captions/train.yaml', 'model_name_or_path': './models/captioning/bert-base-uncased/', 'config_name': '', 'tokenizer_name': '', 'num_hidden_layers': -1, 'hidden_size': -1, 'num_attention_heads': -1, 'intermediate_size': -1, 'img_feature_dim': 512, 'load_partial_weights': False, 'freeze_embedding': False, 'drop_out': 0.1, 'max_seq_length': 64, 'max_seq_a_length': 64, 'max_img_seq_length': 784, 'do_lower_case': True, 'add_od_labels': False, 'od_label_conf': 0.0, 'use_asr': False, 'unique_labels_on': False, 'no_sort_by_conf': False, 'mask_prob': 0.15, 'max_masked_tokens': 3, 'attn_mask_type': 'seq2seq', 'text_mask_type': 'random', 'tag_to_mask': ['noun', 'verb'], 'mask_tag_prob': -1, 'tagger_model_path': 'models/flair/en-pos-ontonotes-fast-v0.5.pt', 'random_mask_prob': 0, 'on_memory': False, 'effective_batch_size': 1, 'per_gpu_train_batch_size': 1, 'num_workers': 4, 'limited_samples': -1, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'warmup_ratio': 0.1, 'scheduler': 'warmup_linear', 'gradient_accumulation_steps': 4, 'num_train_epochs': 10, 'logging_steps': 20, 'save_steps': 3919, 'restore_ratio': 0.05, 'device': device(type='cuda'), 'seed': 88, 'local_rank': 0, 'mixed_precision_method': 'apex', 'zero_opt_stage': -1, 'amp_opt_level': 0, 'deepspeed_fp16': False, 'fairscale_fp16': False, 'pretrained_checkpoint': '', 'debug': False, 'debug_speed': False, 'config': None, 'eval_model_dir': '', 'val_yaml': '../UCA-Dataset/w-captions/val.yaml', 'test_yaml': 'coco_caption/test.yaml', 'do_train': True, 'do_test': False, 'do_eval': False, 'evaluate_during_training': False, 'per_gpu_eval_batch_size': 64, 'mask_img_feat': False, 'max_masked_img_tokens': 10, 'tie_weights': False, 'label_smoothing': 0, 'drop_worst_ratio': 0, 'drop_worst_after': 0, 'max_gen_length': 64, 'output_hidden_states': False, 'num_return_sequences': 1, 'num_beams': 1, 'num_keep_best': 1, 'temperature': 1, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'length_penalty': 1, 'use_cbs': False, 'min_constraints_to_satisfy': 2, 'use_hypo': False, 'decoding_constraint': False, 'remove_bad_endings': False, 'scst': False, 'sc_train_sample_n': 5, 'sc_baseline_type': 'greedy', 'cider_cached_tokens': 'coco_caption/gt/coco-train-words.p', 'max_num_frames': 32, 'img_res': 224, 'patch_size': 32, 'grid_feat': True, 'kinetics': '400', 'pretrained_2d': False, 'vidswin_size': 'base', 'freeze_backbone': False, 'use_checkpoint': False, 'backbone_coef_lr': 0.001, 'reload_pretrained_swin': False, 'learn_mask_enabled': False, 'loss_sparse_w': 0, 'sparse_mask_soft2hard': False, 'transfer_method': -1, 'att_mask_expansion': -1, 'resume_checkpoint': './models/table1/vatex/best-checkpoint/model.bin', 'test_video_fname': 'None', 'num_gpus': 1, 'distributed': False, 'max_iter': 156770, 'max_global_step': 39192, 'global_iters_per_epoch': 3919}
11/16/2025 19:29:15 - INFO - __main__ -   saving args to ./models/table1/uca_finetune/log/args.json
11/16/2025 19:39:53 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 19:39:53 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 19:39:53 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 19:39:53 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 19:39:53 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 19:39:55 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 19:39:58 - INFO - __main__ -   Init model from scratch.
11/16/2025 19:39:58 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 19:39:59 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:40:04 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:40:04 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 19:40:04 - INFO - __main__ -   Total batch size 1
11/16/2025 19:40:04 - INFO - __main__ -   Total training steps 156770
11/16/2025 19:40:04 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:40:06 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:40:06 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 19:45:23 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 19:45:23 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 19:45:23 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 19:45:23 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 19:45:23 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 19:45:25 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 19:45:28 - INFO - __main__ -   Init model from scratch.
11/16/2025 19:45:28 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 19:45:28 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:45:34 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:45:34 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 19:45:34 - INFO - __main__ -   Total batch size 1
11/16/2025 19:45:34 - INFO - __main__ -   Total training steps 156770
11/16/2025 19:45:34 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:45:36 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:45:36 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 19:45:36 - INFO - __main__ -   ==============================key difference
11/16/2025 19:45:36 - INFO - __main__ -   keys in current_args but not in restore_args: total 3, ['config', 'dense_caption', 'dense_caption_num']
11/16/2025 19:45:36 - INFO - __main__ -   keys in restore_args but not in current_args: total 0, []
11/16/2025 19:54:19 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 19:54:19 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 19:54:19 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 19:54:19 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 19:54:19 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 19:54:21 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 19:54:24 - INFO - __main__ -   Init model from scratch.
11/16/2025 19:54:24 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 19:54:25 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:54:30 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:54:30 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 19:54:30 - INFO - __main__ -   Total batch size 1
11/16/2025 19:54:30 - INFO - __main__ -   Total training steps 156770
11/16/2025 19:54:30 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:54:32 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:54:32 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 19:54:32 - INFO - __main__ -   ==============================value difference
11/16/2025 19:59:18 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 19:59:18 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 19:59:18 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 19:59:18 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 19:59:18 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 19:59:20 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 19:59:24 - INFO - __main__ -   Init model from scratch.
11/16/2025 19:59:24 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 19:59:24 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:59:30 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 19:59:30 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 19:59:30 - INFO - __main__ -   Total batch size 1
11/16/2025 19:59:30 - INFO - __main__ -   Total training steps 156770
11/16/2025 19:59:30 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:59:31 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 19:59:31 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 19:59:31 - INFO - __main__ -   ============================== value difference
11/16/2025 19:59:31 - INFO - __main__ -   {
    "device": "[('current_args', device(type='cuda')), ('restore_args', 'cuda')]"
}
11/16/2025 19:59:31 - INFO - __main__ -   Training/evaluation parameters: {'data_dir': 'datasets', 'output_dir': './models/table1/uca_finetune/', 'train_yaml': '../UCA-Dataset/w-captions/train.yaml', 'model_name_or_path': './models/captioning/bert-base-uncased/', 'config_name': '', 'tokenizer_name': '', 'num_hidden_layers': -1, 'hidden_size': -1, 'num_attention_heads': -1, 'intermediate_size': -1, 'img_feature_dim': 512, 'load_partial_weights': False, 'freeze_embedding': False, 'drop_out': 0.1, 'max_seq_length': 64, 'max_seq_a_length': 64, 'max_img_seq_length': 784, 'do_lower_case': True, 'add_od_labels': False, 'od_label_conf': 0.0, 'use_asr': False, 'unique_labels_on': False, 'no_sort_by_conf': False, 'mask_prob': 0.15, 'max_masked_tokens': 3, 'attn_mask_type': 'seq2seq', 'text_mask_type': 'random', 'tag_to_mask': ['noun', 'verb'], 'mask_tag_prob': -1, 'tagger_model_path': 'models/flair/en-pos-ontonotes-fast-v0.5.pt', 'random_mask_prob': 0, 'on_memory': False, 'effective_batch_size': 1, 'per_gpu_train_batch_size': 1, 'num_workers': 4, 'limited_samples': -1, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'warmup_ratio': 0.1, 'scheduler': 'warmup_linear', 'gradient_accumulation_steps': 4, 'num_train_epochs': 10, 'logging_steps': 20, 'save_steps': 3919, 'restore_ratio': 0.05, 'device': device(type='cuda'), 'seed': 88, 'local_rank': 0, 'mixed_precision_method': 'apex', 'zero_opt_stage': -1, 'amp_opt_level': 0, 'deepspeed_fp16': False, 'fairscale_fp16': False, 'pretrained_checkpoint': '', 'debug': False, 'debug_speed': False, 'config': None, 'eval_model_dir': '', 'val_yaml': '../UCA-Dataset/w-captions/val.yaml', 'test_yaml': 'coco_caption/test.yaml', 'do_train': True, 'do_test': False, 'do_eval': False, 'evaluate_during_training': False, 'per_gpu_eval_batch_size': 64, 'mask_img_feat': False, 'max_masked_img_tokens': 10, 'tie_weights': False, 'label_smoothing': 0, 'drop_worst_ratio': 0, 'drop_worst_after': 0, 'max_gen_length': 64, 'output_hidden_states': False, 'num_return_sequences': 1, 'num_beams': 1, 'num_keep_best': 1, 'temperature': 1, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'length_penalty': 1, 'use_cbs': False, 'min_constraints_to_satisfy': 2, 'use_hypo': False, 'decoding_constraint': False, 'remove_bad_endings': False, 'scst': False, 'sc_train_sample_n': 5, 'sc_baseline_type': 'greedy', 'cider_cached_tokens': 'coco_caption/gt/coco-train-words.p', 'max_num_frames': 32, 'img_res': 224, 'patch_size': 32, 'grid_feat': True, 'kinetics': '400', 'pretrained_2d': False, 'vidswin_size': 'base', 'freeze_backbone': False, 'use_checkpoint': False, 'backbone_coef_lr': 0.001, 'reload_pretrained_swin': False, 'learn_mask_enabled': False, 'loss_sparse_w': 0, 'sparse_mask_soft2hard': False, 'transfer_method': -1, 'att_mask_expansion': -1, 'resume_checkpoint': './models/table1/vatex/best-checkpoint/model.bin', 'test_video_fname': 'None', 'dense_caption': False, 'dense_caption_num': 16, 'num_gpus': 1, 'distributed': False, 'max_iter': 156770, 'max_global_step': 39192, 'global_iters_per_epoch': 3919}
11/16/2025 19:59:31 - INFO - __main__ -   saving args to ./models/table1/uca_finetune/log/args.json
11/16/2025 20:04:13 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 20:04:13 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 20:04:13 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 20:04:13 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 20:04:13 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 20:04:15 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 20:04:19 - INFO - __main__ -   Init model from scratch.
11/16/2025 20:04:19 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 20:04:19 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:04:25 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:04:25 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 20:04:25 - INFO - __main__ -   Total batch size 1
11/16/2025 20:04:25 - INFO - __main__ -   Total training steps 156770
11/16/2025 20:04:25 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:04:26 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:04:26 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 20:04:26 - INFO - __main__ -   ============================== value difference
11/16/2025 20:04:26 - INFO - __main__ -   {
    "device": "[('current_args', device(type='cuda')), ('restore_args', 'cuda')]"
}
11/16/2025 20:04:26 - INFO - __main__ -   Training/evaluation parameters: {'data_dir': 'datasets', 'output_dir': './models/table1/uca_finetune/', 'train_yaml': '../UCA-Dataset/w-captions/train.yaml', 'model_name_or_path': './models/captioning/bert-base-uncased/', 'config_name': '', 'tokenizer_name': '', 'num_hidden_layers': -1, 'hidden_size': -1, 'num_attention_heads': -1, 'intermediate_size': -1, 'img_feature_dim': 512, 'load_partial_weights': False, 'freeze_embedding': False, 'drop_out': 0.1, 'max_seq_length': 64, 'max_seq_a_length': 64, 'max_img_seq_length': 784, 'do_lower_case': True, 'add_od_labels': False, 'od_label_conf': 0.0, 'use_asr': False, 'unique_labels_on': False, 'no_sort_by_conf': False, 'mask_prob': 0.15, 'max_masked_tokens': 3, 'attn_mask_type': 'seq2seq', 'text_mask_type': 'random', 'tag_to_mask': ['noun', 'verb'], 'mask_tag_prob': -1, 'tagger_model_path': 'models/flair/en-pos-ontonotes-fast-v0.5.pt', 'random_mask_prob': 0, 'on_memory': False, 'effective_batch_size': 1, 'per_gpu_train_batch_size': 1, 'num_workers': 4, 'limited_samples': -1, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'warmup_ratio': 0.1, 'scheduler': 'warmup_linear', 'gradient_accumulation_steps': 4, 'num_train_epochs': 10, 'logging_steps': 20, 'save_steps': 3919, 'restore_ratio': 0.05, 'device': device(type='cuda'), 'seed': 88, 'local_rank': 0, 'mixed_precision_method': 'apex', 'zero_opt_stage': -1, 'amp_opt_level': 0, 'deepspeed_fp16': False, 'fairscale_fp16': False, 'pretrained_checkpoint': '', 'debug': False, 'debug_speed': False, 'config': None, 'eval_model_dir': '', 'val_yaml': '../UCA-Dataset/w-captions/val.yaml', 'test_yaml': 'coco_caption/test.yaml', 'do_train': True, 'do_test': False, 'do_eval': False, 'evaluate_during_training': False, 'per_gpu_eval_batch_size': 64, 'mask_img_feat': False, 'max_masked_img_tokens': 10, 'tie_weights': False, 'label_smoothing': 0, 'drop_worst_ratio': 0, 'drop_worst_after': 0, 'max_gen_length': 64, 'output_hidden_states': False, 'num_return_sequences': 1, 'num_beams': 1, 'num_keep_best': 1, 'temperature': 1, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'length_penalty': 1, 'use_cbs': False, 'min_constraints_to_satisfy': 2, 'use_hypo': False, 'decoding_constraint': False, 'remove_bad_endings': False, 'scst': False, 'sc_train_sample_n': 5, 'sc_baseline_type': 'greedy', 'cider_cached_tokens': 'coco_caption/gt/coco-train-words.p', 'max_num_frames': 32, 'img_res': 224, 'patch_size': 32, 'grid_feat': True, 'kinetics': '400', 'pretrained_2d': False, 'vidswin_size': 'base', 'freeze_backbone': False, 'use_checkpoint': False, 'backbone_coef_lr': 0.001, 'reload_pretrained_swin': False, 'learn_mask_enabled': False, 'loss_sparse_w': 0, 'sparse_mask_soft2hard': False, 'transfer_method': -1, 'att_mask_expansion': -1, 'resume_checkpoint': './models/table1/vatex/best-checkpoint/model.bin', 'test_video_fname': 'None', 'dense_caption': False, 'dense_caption_num': 16, 'num_gpus': 1, 'distributed': False, 'max_iter': 156770, 'max_global_step': 39192, 'global_iters_per_epoch': 3919}
11/16/2025 20:04:26 - INFO - __main__ -   saving args to ./models/table1/uca_finetune/log/args.json
11/16/2025 20:05:47 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 20:05:47 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 20:05:47 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 20:05:47 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 20:05:47 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 20:05:49 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 20:05:52 - INFO - __main__ -   Init model from scratch.
11/16/2025 20:05:52 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 20:05:53 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:05:58 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:05:58 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 20:05:58 - INFO - __main__ -   Total batch size 1
11/16/2025 20:05:58 - INFO - __main__ -   Total training steps 156770
11/16/2025 20:05:58 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:06:00 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:06:00 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 20:06:00 - INFO - __main__ -   ============================== value difference
11/16/2025 20:06:00 - INFO - __main__ -   {
    "device": "[('current_args', device(type='cuda')), ('restore_args', 'cuda')]"
}
11/16/2025 20:06:00 - INFO - __main__ -   Training/evaluation parameters: {'data_dir': 'datasets', 'output_dir': './models/table1/uca_finetune/', 'train_yaml': '../UCA-Dataset/w-captions/train.yaml', 'model_name_or_path': './models/captioning/bert-base-uncased/', 'config_name': '', 'tokenizer_name': '', 'num_hidden_layers': -1, 'hidden_size': -1, 'num_attention_heads': -1, 'intermediate_size': -1, 'img_feature_dim': 512, 'load_partial_weights': False, 'freeze_embedding': False, 'drop_out': 0.1, 'max_seq_length': 64, 'max_seq_a_length': 64, 'max_img_seq_length': 784, 'do_lower_case': True, 'add_od_labels': False, 'od_label_conf': 0.0, 'use_asr': False, 'unique_labels_on': False, 'no_sort_by_conf': False, 'mask_prob': 0.15, 'max_masked_tokens': 3, 'attn_mask_type': 'seq2seq', 'text_mask_type': 'random', 'tag_to_mask': ['noun', 'verb'], 'mask_tag_prob': -1, 'tagger_model_path': 'models/flair/en-pos-ontonotes-fast-v0.5.pt', 'random_mask_prob': 0, 'on_memory': False, 'effective_batch_size': 1, 'per_gpu_train_batch_size': 1, 'num_workers': 4, 'limited_samples': -1, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'warmup_ratio': 0.1, 'scheduler': 'warmup_linear', 'gradient_accumulation_steps': 4, 'num_train_epochs': 10, 'logging_steps': 20, 'save_steps': 3919, 'restore_ratio': 0.05, 'device': device(type='cuda'), 'seed': 88, 'local_rank': 0, 'mixed_precision_method': 'apex', 'zero_opt_stage': -1, 'amp_opt_level': 0, 'deepspeed_fp16': False, 'fairscale_fp16': False, 'pretrained_checkpoint': '', 'debug': False, 'debug_speed': False, 'config': None, 'eval_model_dir': '', 'val_yaml': '../UCA-Dataset/w-captions/val.yaml', 'test_yaml': 'coco_caption/test.yaml', 'do_train': True, 'do_test': False, 'do_eval': False, 'evaluate_during_training': False, 'per_gpu_eval_batch_size': 64, 'mask_img_feat': False, 'max_masked_img_tokens': 10, 'tie_weights': False, 'label_smoothing': 0, 'drop_worst_ratio': 0, 'drop_worst_after': 0, 'max_gen_length': 64, 'output_hidden_states': False, 'num_return_sequences': 1, 'num_beams': 1, 'num_keep_best': 1, 'temperature': 1, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'length_penalty': 1, 'use_cbs': False, 'min_constraints_to_satisfy': 2, 'use_hypo': False, 'decoding_constraint': False, 'remove_bad_endings': False, 'scst': False, 'sc_train_sample_n': 5, 'sc_baseline_type': 'greedy', 'cider_cached_tokens': 'coco_caption/gt/coco-train-words.p', 'max_num_frames': 32, 'img_res': 224, 'patch_size': 32, 'grid_feat': True, 'kinetics': '400', 'pretrained_2d': False, 'vidswin_size': 'base', 'freeze_backbone': False, 'use_checkpoint': False, 'backbone_coef_lr': 0.001, 'reload_pretrained_swin': False, 'learn_mask_enabled': False, 'loss_sparse_w': 0, 'sparse_mask_soft2hard': False, 'transfer_method': -1, 'att_mask_expansion': -1, 'resume_checkpoint': './models/table1/vatex/best-checkpoint/model.bin', 'test_video_fname': 'None', 'dense_caption': False, 'dense_caption_num': 16, 'num_gpus': 1, 'distributed': False, 'max_iter': 156770, 'max_global_step': 39192, 'global_iters_per_epoch': 3919}
11/16/2025 20:06:00 - INFO - __main__ -   saving args to ./models/table1/uca_finetune/log/args.json
11/16/2025 20:09:09 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 20:09:09 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 20:09:09 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 20:09:09 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 20:09:09 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 20:09:11 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 20:09:15 - INFO - __main__ -   Init model from scratch.
11/16/2025 20:09:15 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 20:09:15 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:09:20 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:09:20 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 20:09:20 - INFO - __main__ -   Total batch size 1
11/16/2025 20:09:20 - INFO - __main__ -   Total training steps 156770
11/16/2025 20:09:20 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:09:22 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:09:22 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 20:09:22 - INFO - __main__ -   ============================== value difference
11/16/2025 20:09:22 - INFO - __main__ -   {
    "device": "[('current_args', device(type='cuda')), ('restore_args', 'cuda')]"
}
11/16/2025 20:09:22 - INFO - __main__ -   Training/evaluation parameters: {'data_dir': 'datasets', 'output_dir': './models/table1/uca_finetune/', 'train_yaml': '../UCA-Dataset/w-captions/train.yaml', 'model_name_or_path': './models/captioning/bert-base-uncased/', 'config_name': '', 'tokenizer_name': '', 'num_hidden_layers': -1, 'hidden_size': -1, 'num_attention_heads': -1, 'intermediate_size': -1, 'img_feature_dim': 512, 'load_partial_weights': False, 'freeze_embedding': False, 'drop_out': 0.1, 'max_seq_length': 64, 'max_seq_a_length': 64, 'max_img_seq_length': 784, 'do_lower_case': True, 'add_od_labels': False, 'od_label_conf': 0.0, 'use_asr': False, 'unique_labels_on': False, 'no_sort_by_conf': False, 'mask_prob': 0.15, 'max_masked_tokens': 3, 'attn_mask_type': 'seq2seq', 'text_mask_type': 'random', 'tag_to_mask': ['noun', 'verb'], 'mask_tag_prob': -1, 'tagger_model_path': 'models/flair/en-pos-ontonotes-fast-v0.5.pt', 'random_mask_prob': 0, 'on_memory': False, 'effective_batch_size': 1, 'per_gpu_train_batch_size': 1, 'num_workers': 4, 'limited_samples': -1, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'warmup_ratio': 0.1, 'scheduler': 'warmup_linear', 'gradient_accumulation_steps': 4, 'num_train_epochs': 10, 'logging_steps': 20, 'save_steps': 3919, 'restore_ratio': 0.05, 'device': device(type='cuda'), 'seed': 88, 'local_rank': 0, 'mixed_precision_method': 'apex', 'zero_opt_stage': -1, 'amp_opt_level': 0, 'deepspeed_fp16': False, 'fairscale_fp16': False, 'pretrained_checkpoint': '', 'debug': False, 'debug_speed': False, 'config': None, 'eval_model_dir': '', 'val_yaml': '../UCA-Dataset/w-captions/val.yaml', 'test_yaml': 'coco_caption/test.yaml', 'do_train': True, 'do_test': False, 'do_eval': False, 'evaluate_during_training': False, 'per_gpu_eval_batch_size': 64, 'mask_img_feat': False, 'max_masked_img_tokens': 10, 'tie_weights': False, 'label_smoothing': 0, 'drop_worst_ratio': 0, 'drop_worst_after': 0, 'max_gen_length': 64, 'output_hidden_states': False, 'num_return_sequences': 1, 'num_beams': 1, 'num_keep_best': 1, 'temperature': 1, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'length_penalty': 1, 'use_cbs': False, 'min_constraints_to_satisfy': 2, 'use_hypo': False, 'decoding_constraint': False, 'remove_bad_endings': False, 'scst': False, 'sc_train_sample_n': 5, 'sc_baseline_type': 'greedy', 'cider_cached_tokens': 'coco_caption/gt/coco-train-words.p', 'max_num_frames': 32, 'img_res': 224, 'patch_size': 32, 'grid_feat': True, 'kinetics': '400', 'pretrained_2d': False, 'vidswin_size': 'base', 'freeze_backbone': False, 'use_checkpoint': False, 'backbone_coef_lr': 0.001, 'reload_pretrained_swin': False, 'learn_mask_enabled': False, 'loss_sparse_w': 0, 'sparse_mask_soft2hard': False, 'transfer_method': -1, 'att_mask_expansion': -1, 'resume_checkpoint': './models/table1/vatex/best-checkpoint/model.bin', 'test_video_fname': 'None', 'dense_caption': False, 'dense_caption_num': 16, 'num_gpus': 1, 'distributed': False, 'max_iter': 156770, 'max_global_step': 39192, 'global_iters_per_epoch': 3919}
11/16/2025 20:09:22 - INFO - __main__ -   saving args to ./models/table1/uca_finetune/log/args.json
11/16/2025 20:13:31 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 20:13:31 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 20:13:31 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 20:13:31 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 20:13:31 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 20:13:33 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 20:13:36 - INFO - __main__ -   Init model from scratch.
11/16/2025 20:13:36 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 20:13:36 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:13:41 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:13:41 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 20:13:41 - INFO - __main__ -   Total batch size 1
11/16/2025 20:13:41 - INFO - __main__ -   Total training steps 156770
11/16/2025 20:13:41 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:13:43 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:13:43 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 20:13:43 - INFO - __main__ -   ============================== value difference
11/16/2025 20:13:43 - INFO - __main__ -   {
    "device": "[('current_args', device(type='cuda')), ('restore_args', 'cuda')]"
}
11/16/2025 20:13:43 - INFO - __main__ -   Training/evaluation parameters: {'data_dir': 'datasets', 'output_dir': './models/table1/uca_finetune/', 'train_yaml': '../UCA-Dataset/w-captions/train.yaml', 'model_name_or_path': './models/captioning/bert-base-uncased/', 'config_name': '', 'tokenizer_name': '', 'num_hidden_layers': -1, 'hidden_size': -1, 'num_attention_heads': -1, 'intermediate_size': -1, 'img_feature_dim': 512, 'load_partial_weights': False, 'freeze_embedding': False, 'drop_out': 0.1, 'max_seq_length': 64, 'max_seq_a_length': 64, 'max_img_seq_length': 784, 'do_lower_case': True, 'add_od_labels': False, 'od_label_conf': 0.0, 'use_asr': False, 'unique_labels_on': False, 'no_sort_by_conf': False, 'mask_prob': 0.15, 'max_masked_tokens': 3, 'attn_mask_type': 'seq2seq', 'text_mask_type': 'random', 'tag_to_mask': ['noun', 'verb'], 'mask_tag_prob': -1, 'tagger_model_path': 'models/flair/en-pos-ontonotes-fast-v0.5.pt', 'random_mask_prob': 0, 'on_memory': False, 'effective_batch_size': 1, 'per_gpu_train_batch_size': 1, 'num_workers': 4, 'limited_samples': -1, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'warmup_ratio': 0.1, 'scheduler': 'warmup_linear', 'gradient_accumulation_steps': 4, 'num_train_epochs': 10, 'logging_steps': 20, 'save_steps': 3919, 'restore_ratio': 0.05, 'device': device(type='cuda'), 'seed': 88, 'local_rank': 0, 'mixed_precision_method': 'apex', 'zero_opt_stage': -1, 'amp_opt_level': 0, 'deepspeed_fp16': False, 'fairscale_fp16': False, 'pretrained_checkpoint': '', 'debug': False, 'debug_speed': False, 'config': None, 'eval_model_dir': '', 'val_yaml': '../UCA-Dataset/w-captions/val.yaml', 'test_yaml': 'coco_caption/test.yaml', 'do_train': True, 'do_test': False, 'do_eval': False, 'evaluate_during_training': False, 'per_gpu_eval_batch_size': 64, 'mask_img_feat': False, 'max_masked_img_tokens': 10, 'tie_weights': False, 'label_smoothing': 0, 'drop_worst_ratio': 0, 'drop_worst_after': 0, 'max_gen_length': 64, 'output_hidden_states': False, 'num_return_sequences': 1, 'num_beams': 1, 'num_keep_best': 1, 'temperature': 1, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'length_penalty': 1, 'use_cbs': False, 'min_constraints_to_satisfy': 2, 'use_hypo': False, 'decoding_constraint': False, 'remove_bad_endings': False, 'scst': False, 'sc_train_sample_n': 5, 'sc_baseline_type': 'greedy', 'cider_cached_tokens': 'coco_caption/gt/coco-train-words.p', 'max_num_frames': 32, 'img_res': 224, 'patch_size': 32, 'grid_feat': True, 'kinetics': '400', 'pretrained_2d': False, 'vidswin_size': 'base', 'freeze_backbone': False, 'use_checkpoint': False, 'backbone_coef_lr': 0.001, 'reload_pretrained_swin': False, 'learn_mask_enabled': False, 'loss_sparse_w': 0, 'sparse_mask_soft2hard': False, 'transfer_method': -1, 'att_mask_expansion': -1, 'resume_checkpoint': './models/table1/vatex/best-checkpoint/model.bin', 'test_video_fname': 'None', 'dense_caption': False, 'dense_caption_num': 16, 'num_gpus': 1, 'distributed': False, 'max_iter': 156770, 'max_global_step': 39192, 'global_iters_per_epoch': 3919}
11/16/2025 20:13:43 - INFO - __main__ -   saving args to ./models/table1/uca_finetune/log/args.json
11/16/2025 20:24:59 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 20:24:59 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 20:24:59 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 20:24:59 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 20:24:59 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 20:25:00 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 20:25:04 - INFO - __main__ -   Init model from scratch.
11/16/2025 20:25:04 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 20:25:04 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:25:10 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:25:10 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 20:25:10 - INFO - __main__ -   Total batch size 1
11/16/2025 20:25:10 - INFO - __main__ -   Total training steps 156770
11/16/2025 20:25:10 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:25:12 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:25:12 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 20:25:12 - INFO - __main__ -   ============================== value difference
11/16/2025 20:25:12 - INFO - __main__ -   {
    "device": "[('current_args', device(type='cuda')), ('restore_args', 'cuda')]"
}
11/16/2025 20:25:12 - INFO - __main__ -   Training/evaluation parameters: {'data_dir': 'datasets', 'output_dir': './models/table1/uca_finetune/', 'train_yaml': '../UCA-Dataset/w-captions/train.yaml', 'model_name_or_path': './models/captioning/bert-base-uncased/', 'config_name': '', 'tokenizer_name': '', 'num_hidden_layers': -1, 'hidden_size': -1, 'num_attention_heads': -1, 'intermediate_size': -1, 'img_feature_dim': 512, 'load_partial_weights': False, 'freeze_embedding': False, 'drop_out': 0.1, 'max_seq_length': 64, 'max_seq_a_length': 64, 'max_img_seq_length': 784, 'do_lower_case': True, 'add_od_labels': False, 'od_label_conf': 0.0, 'use_asr': False, 'unique_labels_on': False, 'no_sort_by_conf': False, 'mask_prob': 0.15, 'max_masked_tokens': 3, 'attn_mask_type': 'seq2seq', 'text_mask_type': 'random', 'tag_to_mask': ['noun', 'verb'], 'mask_tag_prob': -1, 'tagger_model_path': 'models/flair/en-pos-ontonotes-fast-v0.5.pt', 'random_mask_prob': 0, 'on_memory': False, 'effective_batch_size': 1, 'per_gpu_train_batch_size': 1, 'num_workers': 4, 'limited_samples': -1, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'warmup_ratio': 0.1, 'scheduler': 'warmup_linear', 'gradient_accumulation_steps': 4, 'num_train_epochs': 10, 'logging_steps': 20, 'save_steps': 3919, 'restore_ratio': 0.05, 'device': device(type='cuda'), 'seed': 88, 'local_rank': 0, 'mixed_precision_method': 'apex', 'zero_opt_stage': -1, 'amp_opt_level': 0, 'deepspeed_fp16': False, 'fairscale_fp16': False, 'pretrained_checkpoint': '', 'debug': False, 'debug_speed': False, 'config': None, 'eval_model_dir': '', 'val_yaml': '../UCA-Dataset/w-captions/val.yaml', 'test_yaml': 'coco_caption/test.yaml', 'do_train': True, 'do_test': False, 'do_eval': False, 'evaluate_during_training': False, 'per_gpu_eval_batch_size': 64, 'mask_img_feat': False, 'max_masked_img_tokens': 10, 'tie_weights': False, 'label_smoothing': 0, 'drop_worst_ratio': 0, 'drop_worst_after': 0, 'max_gen_length': 64, 'output_hidden_states': False, 'num_return_sequences': 1, 'num_beams': 1, 'num_keep_best': 1, 'temperature': 1, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'length_penalty': 1, 'use_cbs': False, 'min_constraints_to_satisfy': 2, 'use_hypo': False, 'decoding_constraint': False, 'remove_bad_endings': False, 'scst': False, 'sc_train_sample_n': 5, 'sc_baseline_type': 'greedy', 'cider_cached_tokens': 'coco_caption/gt/coco-train-words.p', 'max_num_frames': 32, 'img_res': 224, 'patch_size': 32, 'grid_feat': True, 'kinetics': '400', 'pretrained_2d': False, 'vidswin_size': 'base', 'freeze_backbone': False, 'use_checkpoint': False, 'backbone_coef_lr': 0.001, 'reload_pretrained_swin': False, 'learn_mask_enabled': False, 'loss_sparse_w': 0, 'sparse_mask_soft2hard': False, 'transfer_method': -1, 'att_mask_expansion': -1, 'resume_checkpoint': './models/table1/vatex/best-checkpoint/model.bin', 'test_video_fname': 'None', 'dense_caption': False, 'dense_caption_num': 16, 'num_gpus': 1, 'distributed': False, 'max_iter': 156770, 'max_global_step': 39192, 'global_iters_per_epoch': 3919}
11/16/2025 20:25:12 - INFO - __main__ -   saving args to ./models/table1/uca_finetune/log/args.json
11/16/2025 20:37:36 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 20:37:36 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 20:37:36 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 20:37:36 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 20:37:36 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 20:37:38 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 20:37:42 - INFO - __main__ -   Init model from scratch.
11/16/2025 20:37:42 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 20:37:42 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:37:49 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:37:49 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 20:37:49 - INFO - __main__ -   Total batch size 1
11/16/2025 20:37:49 - INFO - __main__ -   Total training steps 156770
11/16/2025 20:37:49 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:37:50 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:37:50 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 20:37:50 - INFO - __main__ -   ============================== value difference
11/16/2025 20:37:50 - INFO - __main__ -   {
    "device": "[('current_args', device(type='cuda')), ('restore_args', 'cuda')]"
}
11/16/2025 20:37:50 - INFO - __main__ -   Training/evaluation parameters: {'data_dir': 'datasets', 'output_dir': './models/table1/uca_finetune/', 'train_yaml': '../UCA-Dataset/w-captions/train.yaml', 'model_name_or_path': './models/captioning/bert-base-uncased/', 'config_name': '', 'tokenizer_name': '', 'num_hidden_layers': -1, 'hidden_size': -1, 'num_attention_heads': -1, 'intermediate_size': -1, 'img_feature_dim': 512, 'load_partial_weights': False, 'freeze_embedding': False, 'drop_out': 0.1, 'max_seq_length': 64, 'max_seq_a_length': 64, 'max_img_seq_length': 784, 'do_lower_case': True, 'add_od_labels': False, 'od_label_conf': 0.0, 'use_asr': False, 'unique_labels_on': False, 'no_sort_by_conf': False, 'mask_prob': 0.15, 'max_masked_tokens': 3, 'attn_mask_type': 'seq2seq', 'text_mask_type': 'random', 'tag_to_mask': ['noun', 'verb'], 'mask_tag_prob': -1, 'tagger_model_path': 'models/flair/en-pos-ontonotes-fast-v0.5.pt', 'random_mask_prob': 0, 'on_memory': False, 'effective_batch_size': 1, 'per_gpu_train_batch_size': 1, 'num_workers': 4, 'limited_samples': -1, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'warmup_ratio': 0.1, 'scheduler': 'warmup_linear', 'gradient_accumulation_steps': 4, 'num_train_epochs': 10, 'logging_steps': 20, 'save_steps': 3919, 'restore_ratio': 0.05, 'device': device(type='cuda'), 'seed': 88, 'local_rank': 0, 'mixed_precision_method': 'apex', 'zero_opt_stage': -1, 'amp_opt_level': 0, 'deepspeed_fp16': False, 'fairscale_fp16': False, 'pretrained_checkpoint': '', 'debug': False, 'debug_speed': False, 'config': None, 'eval_model_dir': '', 'val_yaml': '../UCA-Dataset/w-captions/val.yaml', 'test_yaml': 'coco_caption/test.yaml', 'do_train': True, 'do_test': False, 'do_eval': False, 'evaluate_during_training': False, 'per_gpu_eval_batch_size': 64, 'mask_img_feat': False, 'max_masked_img_tokens': 10, 'tie_weights': False, 'label_smoothing': 0, 'drop_worst_ratio': 0, 'drop_worst_after': 0, 'max_gen_length': 64, 'output_hidden_states': False, 'num_return_sequences': 1, 'num_beams': 1, 'num_keep_best': 1, 'temperature': 1, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'length_penalty': 1, 'use_cbs': False, 'min_constraints_to_satisfy': 2, 'use_hypo': False, 'decoding_constraint': False, 'remove_bad_endings': False, 'scst': False, 'sc_train_sample_n': 5, 'sc_baseline_type': 'greedy', 'cider_cached_tokens': 'coco_caption/gt/coco-train-words.p', 'max_num_frames': 32, 'img_res': 224, 'patch_size': 32, 'grid_feat': True, 'kinetics': '400', 'pretrained_2d': False, 'vidswin_size': 'base', 'freeze_backbone': False, 'use_checkpoint': False, 'backbone_coef_lr': 0.001, 'reload_pretrained_swin': False, 'learn_mask_enabled': False, 'loss_sparse_w': 0, 'sparse_mask_soft2hard': False, 'transfer_method': -1, 'att_mask_expansion': -1, 'resume_checkpoint': './models/table1/vatex/best-checkpoint/model.bin', 'test_video_fname': 'None', 'dense_caption': False, 'dense_caption_num': 16, 'num_gpus': 1, 'distributed': False, 'max_iter': 156770, 'max_global_step': 39192, 'global_iters_per_epoch': 3919}
11/16/2025 20:37:50 - INFO - __main__ -   saving args to ./models/table1/uca_finetune/log/args.json
11/16/2025 20:40:23 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 20:40:23 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 20:40:23 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 20:40:23 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 20:40:23 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 20:40:25 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 20:40:28 - INFO - __main__ -   Init model from scratch.
11/16/2025 20:40:28 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 20:40:29 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:40:34 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:40:34 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 20:40:34 - INFO - __main__ -   Total batch size 1
11/16/2025 20:40:34 - INFO - __main__ -   Total training steps 156770
11/16/2025 20:40:34 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:40:35 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:40:35 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 20:40:35 - INFO - __main__ -   ============================== value difference
11/16/2025 20:40:35 - INFO - __main__ -   {
    "device": "[('current_args', device(type='cuda')), ('restore_args', 'cuda')]"
}
11/16/2025 20:40:35 - INFO - __main__ -   Training/evaluation parameters: {'data_dir': 'datasets', 'output_dir': './models/table1/uca_finetune/', 'train_yaml': '../UCA-Dataset/w-captions/train.yaml', 'model_name_or_path': './models/captioning/bert-base-uncased/', 'config_name': '', 'tokenizer_name': '', 'num_hidden_layers': -1, 'hidden_size': -1, 'num_attention_heads': -1, 'intermediate_size': -1, 'img_feature_dim': 512, 'load_partial_weights': False, 'freeze_embedding': False, 'drop_out': 0.1, 'max_seq_length': 64, 'max_seq_a_length': 64, 'max_img_seq_length': 784, 'do_lower_case': True, 'add_od_labels': False, 'od_label_conf': 0.0, 'use_asr': False, 'unique_labels_on': False, 'no_sort_by_conf': False, 'mask_prob': 0.15, 'max_masked_tokens': 3, 'attn_mask_type': 'seq2seq', 'text_mask_type': 'random', 'tag_to_mask': ['noun', 'verb'], 'mask_tag_prob': -1, 'tagger_model_path': 'models/flair/en-pos-ontonotes-fast-v0.5.pt', 'random_mask_prob': 0, 'on_memory': False, 'effective_batch_size': 1, 'per_gpu_train_batch_size': 1, 'num_workers': 4, 'limited_samples': -1, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'warmup_ratio': 0.1, 'scheduler': 'warmup_linear', 'gradient_accumulation_steps': 4, 'num_train_epochs': 10, 'logging_steps': 20, 'save_steps': 3919, 'restore_ratio': 0.05, 'device': device(type='cuda'), 'seed': 88, 'local_rank': 0, 'mixed_precision_method': 'apex', 'zero_opt_stage': -1, 'amp_opt_level': 0, 'deepspeed_fp16': False, 'fairscale_fp16': False, 'pretrained_checkpoint': '', 'debug': False, 'debug_speed': False, 'config': None, 'eval_model_dir': '', 'val_yaml': '../UCA-Dataset/w-captions/val.yaml', 'test_yaml': 'coco_caption/test.yaml', 'do_train': True, 'do_test': False, 'do_eval': False, 'evaluate_during_training': False, 'per_gpu_eval_batch_size': 64, 'mask_img_feat': False, 'max_masked_img_tokens': 10, 'tie_weights': False, 'label_smoothing': 0, 'drop_worst_ratio': 0, 'drop_worst_after': 0, 'max_gen_length': 64, 'output_hidden_states': False, 'num_return_sequences': 1, 'num_beams': 1, 'num_keep_best': 1, 'temperature': 1, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'length_penalty': 1, 'use_cbs': False, 'min_constraints_to_satisfy': 2, 'use_hypo': False, 'decoding_constraint': False, 'remove_bad_endings': False, 'scst': False, 'sc_train_sample_n': 5, 'sc_baseline_type': 'greedy', 'cider_cached_tokens': 'coco_caption/gt/coco-train-words.p', 'max_num_frames': 32, 'img_res': 224, 'patch_size': 32, 'grid_feat': True, 'kinetics': '400', 'pretrained_2d': False, 'vidswin_size': 'base', 'freeze_backbone': False, 'use_checkpoint': False, 'backbone_coef_lr': 0.001, 'reload_pretrained_swin': False, 'learn_mask_enabled': False, 'loss_sparse_w': 0, 'sparse_mask_soft2hard': False, 'transfer_method': -1, 'att_mask_expansion': -1, 'resume_checkpoint': './models/table1/vatex/best-checkpoint/model.bin', 'test_video_fname': 'None', 'dense_caption': False, 'dense_caption_num': 16, 'num_gpus': 1, 'distributed': False, 'max_iter': 156770, 'max_global_step': 39192, 'global_iters_per_epoch': 3919}
11/16/2025 20:40:35 - INFO - __main__ -   saving args to ./models/table1/uca_finetune/log/args.json
11/16/2025 20:46:48 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 20:46:48 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 20:46:48 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 20:46:48 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 20:46:48 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 20:46:50 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 20:46:54 - INFO - __main__ -   Init model from scratch.
11/16/2025 20:46:54 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 20:46:54 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:47:00 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:47:00 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 20:47:00 - INFO - __main__ -   Total batch size 1
11/16/2025 20:47:00 - INFO - __main__ -   Total training steps 156770
11/16/2025 20:47:00 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:47:01 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:47:01 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 20:47:01 - INFO - __main__ -   ============================== value difference
11/16/2025 20:47:01 - INFO - __main__ -   {
    "device": "[('current_args', device(type='cuda')), ('restore_args', 'cuda')]"
}
11/16/2025 20:47:01 - INFO - __main__ -   Training/evaluation parameters: {'data_dir': 'datasets', 'output_dir': './models/table1/uca_finetune/', 'train_yaml': '../UCA-Dataset/w-captions/train.yaml', 'model_name_or_path': './models/captioning/bert-base-uncased/', 'config_name': '', 'tokenizer_name': '', 'num_hidden_layers': -1, 'hidden_size': -1, 'num_attention_heads': -1, 'intermediate_size': -1, 'img_feature_dim': 512, 'load_partial_weights': False, 'freeze_embedding': False, 'drop_out': 0.1, 'max_seq_length': 64, 'max_seq_a_length': 64, 'max_img_seq_length': 784, 'do_lower_case': True, 'add_od_labels': False, 'od_label_conf': 0.0, 'use_asr': False, 'unique_labels_on': False, 'no_sort_by_conf': False, 'mask_prob': 0.15, 'max_masked_tokens': 3, 'attn_mask_type': 'seq2seq', 'text_mask_type': 'random', 'tag_to_mask': ['noun', 'verb'], 'mask_tag_prob': -1, 'tagger_model_path': 'models/flair/en-pos-ontonotes-fast-v0.5.pt', 'random_mask_prob': 0, 'on_memory': False, 'effective_batch_size': 1, 'per_gpu_train_batch_size': 1, 'num_workers': 4, 'limited_samples': -1, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'warmup_ratio': 0.1, 'scheduler': 'warmup_linear', 'gradient_accumulation_steps': 4, 'num_train_epochs': 10, 'logging_steps': 20, 'save_steps': 3919, 'restore_ratio': 0.05, 'device': device(type='cuda'), 'seed': 88, 'local_rank': 0, 'mixed_precision_method': 'apex', 'zero_opt_stage': -1, 'amp_opt_level': 0, 'deepspeed_fp16': False, 'fairscale_fp16': False, 'pretrained_checkpoint': '', 'debug': False, 'debug_speed': False, 'config': None, 'eval_model_dir': '', 'val_yaml': '../UCA-Dataset/w-captions/val.yaml', 'test_yaml': 'coco_caption/test.yaml', 'do_train': True, 'do_test': False, 'do_eval': False, 'evaluate_during_training': False, 'per_gpu_eval_batch_size': 64, 'mask_img_feat': False, 'max_masked_img_tokens': 10, 'tie_weights': False, 'label_smoothing': 0, 'drop_worst_ratio': 0, 'drop_worst_after': 0, 'max_gen_length': 64, 'output_hidden_states': False, 'num_return_sequences': 1, 'num_beams': 1, 'num_keep_best': 1, 'temperature': 1, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'length_penalty': 1, 'use_cbs': False, 'min_constraints_to_satisfy': 2, 'use_hypo': False, 'decoding_constraint': False, 'remove_bad_endings': False, 'scst': False, 'sc_train_sample_n': 5, 'sc_baseline_type': 'greedy', 'cider_cached_tokens': 'coco_caption/gt/coco-train-words.p', 'max_num_frames': 32, 'img_res': 224, 'patch_size': 32, 'grid_feat': True, 'kinetics': '400', 'pretrained_2d': False, 'vidswin_size': 'base', 'freeze_backbone': False, 'use_checkpoint': False, 'backbone_coef_lr': 0.001, 'reload_pretrained_swin': False, 'learn_mask_enabled': False, 'loss_sparse_w': 0, 'sparse_mask_soft2hard': False, 'transfer_method': -1, 'att_mask_expansion': -1, 'resume_checkpoint': './models/table1/vatex/best-checkpoint/model.bin', 'test_video_fname': 'None', 'dense_caption': False, 'dense_caption_num': 16, 'num_gpus': 1, 'distributed': False, 'max_iter': 156770, 'max_global_step': 39192, 'global_iters_per_epoch': 3919}
11/16/2025 20:47:01 - INFO - __main__ -   saving args to ./models/table1/uca_finetune/log/args.json
11/16/2025 20:51:19 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 20:51:19 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 20:51:19 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 20:51:19 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 20:51:19 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 20:51:21 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 20:51:25 - INFO - __main__ -   Init model from scratch.
11/16/2025 20:51:25 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 20:51:25 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:51:32 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:51:32 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 20:51:32 - INFO - __main__ -   Total batch size 1
11/16/2025 20:51:32 - INFO - __main__ -   Total training steps 156770
11/16/2025 20:51:32 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:51:33 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:51:33 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 20:51:33 - INFO - __main__ -   ============================== value difference
11/16/2025 20:51:33 - INFO - __main__ -   {
    "device": "[('current_args', device(type='cuda')), ('restore_args', 'cuda')]"
}
11/16/2025 20:51:33 - INFO - __main__ -   Training/evaluation parameters: {'data_dir': 'datasets', 'output_dir': './models/table1/uca_finetune/', 'train_yaml': '../UCA-Dataset/w-captions/train.yaml', 'model_name_or_path': './models/captioning/bert-base-uncased/', 'config_name': '', 'tokenizer_name': '', 'num_hidden_layers': -1, 'hidden_size': -1, 'num_attention_heads': -1, 'intermediate_size': -1, 'img_feature_dim': 512, 'load_partial_weights': False, 'freeze_embedding': False, 'drop_out': 0.1, 'max_seq_length': 64, 'max_seq_a_length': 64, 'max_img_seq_length': 784, 'do_lower_case': True, 'add_od_labels': False, 'od_label_conf': 0.0, 'use_asr': False, 'unique_labels_on': False, 'no_sort_by_conf': False, 'mask_prob': 0.15, 'max_masked_tokens': 3, 'attn_mask_type': 'seq2seq', 'text_mask_type': 'random', 'tag_to_mask': ['noun', 'verb'], 'mask_tag_prob': -1, 'tagger_model_path': 'models/flair/en-pos-ontonotes-fast-v0.5.pt', 'random_mask_prob': 0, 'on_memory': False, 'effective_batch_size': 1, 'per_gpu_train_batch_size': 1, 'num_workers': 4, 'limited_samples': -1, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'warmup_ratio': 0.1, 'scheduler': 'warmup_linear', 'gradient_accumulation_steps': 4, 'num_train_epochs': 10, 'logging_steps': 20, 'save_steps': 3919, 'restore_ratio': 0.05, 'device': device(type='cuda'), 'seed': 88, 'local_rank': 0, 'mixed_precision_method': 'apex', 'zero_opt_stage': -1, 'amp_opt_level': 0, 'deepspeed_fp16': False, 'fairscale_fp16': False, 'pretrained_checkpoint': '', 'debug': False, 'debug_speed': False, 'config': None, 'eval_model_dir': '', 'val_yaml': '../UCA-Dataset/w-captions/val.yaml', 'test_yaml': 'coco_caption/test.yaml', 'do_train': True, 'do_test': False, 'do_eval': False, 'evaluate_during_training': False, 'per_gpu_eval_batch_size': 64, 'mask_img_feat': False, 'max_masked_img_tokens': 10, 'tie_weights': False, 'label_smoothing': 0, 'drop_worst_ratio': 0, 'drop_worst_after': 0, 'max_gen_length': 64, 'output_hidden_states': False, 'num_return_sequences': 1, 'num_beams': 1, 'num_keep_best': 1, 'temperature': 1, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'length_penalty': 1, 'use_cbs': False, 'min_constraints_to_satisfy': 2, 'use_hypo': False, 'decoding_constraint': False, 'remove_bad_endings': False, 'scst': False, 'sc_train_sample_n': 5, 'sc_baseline_type': 'greedy', 'cider_cached_tokens': 'coco_caption/gt/coco-train-words.p', 'max_num_frames': 32, 'img_res': 224, 'patch_size': 32, 'grid_feat': True, 'kinetics': '400', 'pretrained_2d': False, 'vidswin_size': 'base', 'freeze_backbone': False, 'use_checkpoint': False, 'backbone_coef_lr': 0.001, 'reload_pretrained_swin': False, 'learn_mask_enabled': False, 'loss_sparse_w': 0, 'sparse_mask_soft2hard': False, 'transfer_method': -1, 'att_mask_expansion': -1, 'resume_checkpoint': './models/table1/vatex/best-checkpoint/model.bin', 'test_video_fname': 'None', 'dense_caption': False, 'dense_caption_num': 16, 'num_gpus': 1, 'distributed': False, 'max_iter': 156770, 'max_global_step': 39192, 'global_iters_per_epoch': 3919}
11/16/2025 20:51:33 - INFO - __main__ -   saving args to ./models/table1/uca_finetune/log/args.json
11/16/2025 20:51:34 - INFO - __main__ -   input_ids = torch.Size([1, 64])
11/16/2025 20:51:34 - INFO - __main__ -   attention_mask = torch.Size([1, 848, 848])
11/16/2025 20:51:34 - INFO - __main__ -   token_type_ids = torch.Size([1, 64])
11/16/2025 20:51:34 - INFO - __main__ -   img_feats = torch.Size([1, 32, 3, 224, 224])
11/16/2025 20:51:34 - INFO - __main__ -   masked_pos = torch.Size([1, 64])
11/16/2025 20:51:34 - INFO - __main__ -   masked_ids = torch.Size([1, 3])
11/16/2025 20:57:56 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 20:57:56 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 20:57:56 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 20:57:56 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 20:57:56 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 20:57:58 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 20:58:02 - INFO - __main__ -   Init model from scratch.
11/16/2025 20:58:02 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 20:58:02 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:58:08 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 20:58:08 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 20:58:08 - INFO - __main__ -   Total batch size 1
11/16/2025 20:58:08 - INFO - __main__ -   Total training steps 156770
11/16/2025 20:58:08 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:58:10 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 20:58:10 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 20:58:10 - INFO - __main__ -   ============================== value difference
11/16/2025 20:58:10 - INFO - __main__ -   {
    "device": "[('current_args', device(type='cuda')), ('restore_args', 'cuda')]"
}
11/16/2025 20:58:10 - INFO - __main__ -   Training/evaluation parameters: {'data_dir': 'datasets', 'output_dir': './models/table1/uca_finetune/', 'train_yaml': '../UCA-Dataset/w-captions/train.yaml', 'model_name_or_path': './models/captioning/bert-base-uncased/', 'config_name': '', 'tokenizer_name': '', 'num_hidden_layers': -1, 'hidden_size': -1, 'num_attention_heads': -1, 'intermediate_size': -1, 'img_feature_dim': 512, 'load_partial_weights': False, 'freeze_embedding': False, 'drop_out': 0.1, 'max_seq_length': 64, 'max_seq_a_length': 64, 'max_img_seq_length': 784, 'do_lower_case': True, 'add_od_labels': False, 'od_label_conf': 0.0, 'use_asr': False, 'unique_labels_on': False, 'no_sort_by_conf': False, 'mask_prob': 0.15, 'max_masked_tokens': 3, 'attn_mask_type': 'seq2seq', 'text_mask_type': 'random', 'tag_to_mask': ['noun', 'verb'], 'mask_tag_prob': -1, 'tagger_model_path': 'models/flair/en-pos-ontonotes-fast-v0.5.pt', 'random_mask_prob': 0, 'on_memory': False, 'effective_batch_size': 1, 'per_gpu_train_batch_size': 1, 'num_workers': 4, 'limited_samples': -1, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'warmup_ratio': 0.1, 'scheduler': 'warmup_linear', 'gradient_accumulation_steps': 4, 'num_train_epochs': 10, 'logging_steps': 20, 'save_steps': 3919, 'restore_ratio': 0.05, 'device': device(type='cuda'), 'seed': 88, 'local_rank': 0, 'mixed_precision_method': 'apex', 'zero_opt_stage': -1, 'amp_opt_level': 0, 'deepspeed_fp16': False, 'fairscale_fp16': False, 'pretrained_checkpoint': '', 'debug': False, 'debug_speed': False, 'config': None, 'eval_model_dir': '', 'val_yaml': '../UCA-Dataset/w-captions/val.yaml', 'test_yaml': 'coco_caption/test.yaml', 'do_train': True, 'do_test': False, 'do_eval': False, 'evaluate_during_training': False, 'per_gpu_eval_batch_size': 64, 'mask_img_feat': False, 'max_masked_img_tokens': 10, 'tie_weights': False, 'label_smoothing': 0, 'drop_worst_ratio': 0, 'drop_worst_after': 0, 'max_gen_length': 64, 'output_hidden_states': False, 'num_return_sequences': 1, 'num_beams': 1, 'num_keep_best': 1, 'temperature': 1, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'length_penalty': 1, 'use_cbs': False, 'min_constraints_to_satisfy': 2, 'use_hypo': False, 'decoding_constraint': False, 'remove_bad_endings': False, 'scst': False, 'sc_train_sample_n': 5, 'sc_baseline_type': 'greedy', 'cider_cached_tokens': 'coco_caption/gt/coco-train-words.p', 'max_num_frames': 32, 'img_res': 224, 'patch_size': 32, 'grid_feat': True, 'kinetics': '400', 'pretrained_2d': False, 'vidswin_size': 'base', 'freeze_backbone': False, 'use_checkpoint': False, 'backbone_coef_lr': 0.001, 'reload_pretrained_swin': False, 'learn_mask_enabled': False, 'loss_sparse_w': 0, 'sparse_mask_soft2hard': False, 'transfer_method': -1, 'att_mask_expansion': -1, 'resume_checkpoint': './models/table1/vatex/best-checkpoint/model.bin', 'test_video_fname': 'None', 'dense_caption': False, 'dense_caption_num': 16, 'num_gpus': 1, 'distributed': False, 'max_iter': 156770, 'max_global_step': 39192, 'global_iters_per_epoch': 3919}
11/16/2025 20:58:10 - INFO - __main__ -   saving args to ./models/table1/uca_finetune/log/args.json
11/16/2025 20:58:10 - INFO - __main__ -   input_ids = torch.Size([1, 64])
11/16/2025 20:58:10 - INFO - __main__ -   attention_mask = torch.Size([1, 848, 848])
11/16/2025 20:58:10 - INFO - __main__ -   token_type_ids = torch.Size([1, 64])
11/16/2025 20:58:10 - INFO - __main__ -   img_feats = torch.Size([1, 32, 3, 224, 224])
11/16/2025 20:58:10 - INFO - __main__ -   masked_pos = torch.Size([1, 64])
11/16/2025 20:58:10 - INFO - __main__ -   masked_ids = torch.Size([1, 3])
11/16/2025 21:03:08 - INFO - __main__ -   Pytorch version is: 2.7.0
11/16/2025 21:03:08 - INFO - __main__ -   Cuda version is: 12.8
11/16/2025 21:03:08 - INFO - __main__ -   cuDNN version is : 90800
11/16/2025 21:03:08 - INFO - __main__ -   video swin (config path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/src/modeling/video_swin/swin_base_patch244_window877_kinetics400_22k.py
11/16/2025 21:03:08 - INFO - __main__ -   video swin (model path): /home/ubuntu/Multimodal-Anomaly-Detection-Survelliance-Videos/SwinBERT/models/video_swin_transformer/swin_base_patch244_window877_kinetics400_22k.pth
11/16/2025 21:03:10 - INFO - __main__ -   Update config parameter img_feature_dim: -1 -> 512
11/16/2025 21:03:14 - INFO - __main__ -   Init model from scratch.
11/16/2025 21:03:14 - INFO - __main__ -   Model total parameters: 136,106,810
11/16/2025 21:03:14 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/train.yaml
11/16/2025 21:03:20 - INFO - __main__ -   Loaded 15677 video-caption pairs from ../UCA-Dataset/w-captions/train.yaml
11/16/2025 21:03:20 - INFO - __main__ -   Train with 1 samples per GPU
11/16/2025 21:03:20 - INFO - __main__ -   Total batch size 1
11/16/2025 21:03:20 - INFO - __main__ -   Total training steps 156770
11/16/2025 21:03:20 - INFO - __main__ -   YAML file: ../UCA-Dataset/w-captions/val.yaml
11/16/2025 21:03:22 - INFO - __main__ -   Loaded 3534 video-caption pairs from ../UCA-Dataset/w-captions/val.yaml
11/16/2025 21:03:22 - INFO - __main__ -   Using native PyTorch AMP instead of Apex.
11/16/2025 21:03:22 - INFO - __main__ -   ============================== value difference
11/16/2025 21:03:22 - INFO - __main__ -   {
    "device": "[('current_args', device(type='cuda')), ('restore_args', 'cuda')]"
}
11/16/2025 21:03:22 - INFO - __main__ -   Training/evaluation parameters: {'data_dir': 'datasets', 'output_dir': './models/table1/uca_finetune/', 'train_yaml': '../UCA-Dataset/w-captions/train.yaml', 'model_name_or_path': './models/captioning/bert-base-uncased/', 'config_name': '', 'tokenizer_name': '', 'num_hidden_layers': -1, 'hidden_size': -1, 'num_attention_heads': -1, 'intermediate_size': -1, 'img_feature_dim': 512, 'load_partial_weights': False, 'freeze_embedding': False, 'drop_out': 0.1, 'max_seq_length': 64, 'max_seq_a_length': 64, 'max_img_seq_length': 784, 'do_lower_case': True, 'add_od_labels': False, 'od_label_conf': 0.0, 'use_asr': False, 'unique_labels_on': False, 'no_sort_by_conf': False, 'mask_prob': 0.15, 'max_masked_tokens': 3, 'attn_mask_type': 'seq2seq', 'text_mask_type': 'random', 'tag_to_mask': ['noun', 'verb'], 'mask_tag_prob': -1, 'tagger_model_path': 'models/flair/en-pos-ontonotes-fast-v0.5.pt', 'random_mask_prob': 0, 'on_memory': False, 'effective_batch_size': 1, 'per_gpu_train_batch_size': 1, 'num_workers': 4, 'limited_samples': -1, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'warmup_ratio': 0.1, 'scheduler': 'warmup_linear', 'gradient_accumulation_steps': 4, 'num_train_epochs': 10, 'logging_steps': 20, 'save_steps': 3919, 'restore_ratio': 0.05, 'device': device(type='cuda'), 'seed': 88, 'local_rank': 0, 'mixed_precision_method': 'apex', 'zero_opt_stage': -1, 'amp_opt_level': 0, 'deepspeed_fp16': False, 'fairscale_fp16': False, 'pretrained_checkpoint': '', 'debug': False, 'debug_speed': False, 'config': None, 'eval_model_dir': '', 'val_yaml': '../UCA-Dataset/w-captions/val.yaml', 'test_yaml': 'coco_caption/test.yaml', 'do_train': True, 'do_test': False, 'do_eval': False, 'evaluate_during_training': False, 'per_gpu_eval_batch_size': 64, 'mask_img_feat': False, 'max_masked_img_tokens': 10, 'tie_weights': False, 'label_smoothing': 0, 'drop_worst_ratio': 0, 'drop_worst_after': 0, 'max_gen_length': 64, 'output_hidden_states': False, 'num_return_sequences': 1, 'num_beams': 1, 'num_keep_best': 1, 'temperature': 1, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'length_penalty': 1, 'use_cbs': False, 'min_constraints_to_satisfy': 2, 'use_hypo': False, 'decoding_constraint': False, 'remove_bad_endings': False, 'scst': False, 'sc_train_sample_n': 5, 'sc_baseline_type': 'greedy', 'cider_cached_tokens': 'coco_caption/gt/coco-train-words.p', 'max_num_frames': 32, 'img_res': 224, 'patch_size': 32, 'grid_feat': True, 'kinetics': '400', 'pretrained_2d': False, 'vidswin_size': 'base', 'freeze_backbone': False, 'use_checkpoint': False, 'backbone_coef_lr': 0.001, 'reload_pretrained_swin': False, 'learn_mask_enabled': False, 'loss_sparse_w': 0, 'sparse_mask_soft2hard': False, 'transfer_method': -1, 'att_mask_expansion': -1, 'resume_checkpoint': './models/table1/vatex/best-checkpoint/model.bin', 'test_video_fname': 'None', 'dense_caption': False, 'dense_caption_num': 16, 'num_gpus': 1, 'distributed': False, 'max_iter': 156770, 'max_global_step': 39192, 'global_iters_per_epoch': 3919}
11/16/2025 21:03:22 - INFO - __main__ -   saving args to ./models/table1/uca_finetune/log/args.json
11/16/2025 21:03:23 - INFO - __main__ -   input_ids = torch.Size([1, 64])
11/16/2025 21:03:23 - INFO - __main__ -   attention_mask = torch.Size([1, 848, 848])
11/16/2025 21:03:23 - INFO - __main__ -   token_type_ids = torch.Size([1, 64])
11/16/2025 21:03:23 - INFO - __main__ -   img_feats = torch.Size([1, 32, 3, 224, 224])
11/16/2025 21:03:23 - INFO - __main__ -   masked_pos = torch.Size([1, 64])
11/16/2025 21:03:23 - INFO - __main__ -   masked_ids = torch.Size([1, 3])
11/16/2025 21:03:27 - INFO - __main__ -   ModelSaver save trial NO. 0
11/16/2025 21:03:32 - INFO - __main__ -   Save checkpoint to ./models/table1/uca_finetune/checkpoint-0-1
11/16/2025 21:04:08 - INFO - __main__ -   eta: 1 day, 4:04:49  iter: 80  global_step: 20  speed: 0.4 images/sec  loss: 10.5172 (10.4329)  acc: 0.0000 (0.0000)  batch_time: 0.4681 (0.4768)  data_time: 0.0005 (0.0005)  lr (Visual Encoder): 1.00e-08  lr (LM): 1.45e-07  max mem: 10867
11/16/2025 21:04:52 - INFO - __main__ -   eta: 1 day, 4:40:22  iter: 160  global_step: 40  speed: 0.5 images/sec  loss: 10.4127 (10.4357)  acc: 0.0000 (0.0000)  batch_time: 0.4728 (0.5132)  data_time: 0.0005 (0.0356)  lr (Visual Encoder): 1.00e-08  lr (LM): 2.99e-07  max mem: 10867
11/16/2025 21:05:30 - INFO - __main__ -   eta: 1 day, 4:40:49  iter: 240  global_step: 60  speed: 0.5 images/sec  loss: 10.3037 (10.4002)  acc: 0.0000 (0.0000)  batch_time: 0.4759 (0.5028)  data_time: 0.0005 (0.0237)  lr (Visual Encoder): 1.00e-08  lr (LM): 4.52e-07  max mem: 10867
11/16/2025 21:06:09 - INFO - __main__ -   eta: 1 day, 4:51:44  iter: 320  global_step: 80  speed: 0.5 images/sec  loss: 10.2868 (10.3671)  acc: 0.0000 (0.0000)  batch_time: 0.4862 (0.4987)  data_time: 0.0005 (0.0178)  lr (Visual Encoder): 1.00e-08  lr (LM): 6.05e-07  max mem: 10867
11/16/2025 21:06:48 - INFO - __main__ -   eta: 1 day, 4:58:44  iter: 400  global_step: 100  speed: 0.5 images/sec  loss: 10.0051 (10.3200)  acc: 0.0000 (0.0008)  batch_time: 0.4827 (0.4969)  data_time: 0.0004 (0.0143)  lr (Visual Encoder): 1.00e-08  lr (LM): 7.58e-07  max mem: 10867
11/16/2025 21:07:28 - INFO - __main__ -   eta: 1 day, 4:52:59  iter: 480  global_step: 120  speed: 0.5 images/sec  loss: 10.1817 (10.2658)  acc: 0.0000 (0.0028)  batch_time: 0.4849 (0.4960)  data_time: 0.0005 (0.0120)  lr (Visual Encoder): 1.00e-08  lr (LM): 9.11e-07  max mem: 10867
11/16/2025 21:08:07 - INFO - __main__ -   eta: 1 day, 4:48:07  iter: 560  global_step: 140  speed: 0.5 images/sec  loss: 9.9370 (10.2188)  acc: 0.0000 (0.0146)  batch_time: 0.4858 (0.4956)  data_time: 0.0005 (0.0104)  lr (Visual Encoder): 1.00e-08  lr (LM): 1.06e-06  max mem: 10867
11/16/2025 21:08:47 - INFO - __main__ -   eta: 1 day, 4:57:09  iter: 640  global_step: 160  speed: 0.5 images/sec  loss: 9.8767 (10.1729)  acc: 0.0000 (0.0273)  batch_time: 0.4839 (0.4954)  data_time: 0.0005 (0.0091)  lr (Visual Encoder): 1.00e-08  lr (LM): 1.22e-06  max mem: 10867
11/16/2025 21:09:26 - INFO - __main__ -   eta: 1 day, 4:48:24  iter: 720  global_step: 180  speed: 0.5 images/sec  loss: 10.3024 (10.0950)  acc: 0.0000 (0.0440)  batch_time: 0.4866 (0.4954)  data_time: 0.0004 (0.0081)  lr (Visual Encoder): 1.00e-08  lr (LM): 1.37e-06  max mem: 10867
11/16/2025 21:10:06 - INFO - __main__ -   eta: 1 day, 4:46:59  iter: 800  global_step: 200  speed: 0.5 images/sec  loss: 9.5578 (10.0294)  acc: 0.0000 (0.0521)  batch_time: 0.4887 (0.4953)  data_time: 0.0005 (0.0074)  lr (Visual Encoder): 1.00e-08  lr (LM): 1.52e-06  max mem: 10867
11/16/2025 21:10:45 - INFO - __main__ -   eta: 1 day, 5:20:15  iter: 880  global_step: 220  speed: 0.5 images/sec  loss: 9.3686 (9.9607)  acc: 0.0000 (0.0581)  batch_time: 0.4851 (0.4953)  data_time: 0.0004 (0.0067)  lr (Visual Encoder): 1.00e-08  lr (LM): 1.68e-06  max mem: 10867
11/16/2025 21:11:25 - INFO - __main__ -   eta: 1 day, 5:03:07  iter: 960  global_step: 240  speed: 0.5 images/sec  loss: 8.5396 (9.8618)  acc: 0.0000 (0.0696)  batch_time: 0.4870 (0.4953)  data_time: 0.0005 (0.0062)  lr (Visual Encoder): 1.00e-08  lr (LM): 1.83e-06  max mem: 10867
11/16/2025 21:12:05 - INFO - __main__ -   eta: 1 day, 4:45:57  iter: 1040  global_step: 260  speed: 0.5 images/sec  loss: 8.2965 (9.8031)  acc: 0.0000 (0.0723)  batch_time: 0.4892 (0.4953)  data_time: 0.0005 (0.0058)  lr (Visual Encoder): 1.00e-08  lr (LM): 1.98e-06  max mem: 10867
11/16/2025 21:12:44 - INFO - __main__ -   eta: 1 day, 4:52:39  iter: 1120  global_step: 280  speed: 0.5 images/sec  loss: 8.5038 (9.7197)  acc: 0.0000 (0.0777)  batch_time: 0.4867 (0.4954)  data_time: 0.0004 (0.0054)  lr (Visual Encoder): 1.00e-08  lr (LM): 2.14e-06  max mem: 10867
11/16/2025 21:13:24 - INFO - __main__ -   eta: 1 day, 4:33:00  iter: 1200  global_step: 300  speed: 0.5 images/sec  loss: 8.3361 (9.6548)  acc: 0.0000 (0.0792)  batch_time: 0.4885 (0.4954)  data_time: 0.0004 (0.0051)  lr (Visual Encoder): 1.00e-08  lr (LM): 2.29e-06  max mem: 10867
11/16/2025 21:14:04 - INFO - __main__ -   eta: 1 day, 5:02:29  iter: 1280  global_step: 320  speed: 0.5 images/sec  loss: 7.7448 (9.5929)  acc: 0.0000 (0.0815)  batch_time: 0.4843 (0.4955)  data_time: 0.0004 (0.0048)  lr (Visual Encoder): 1.00e-08  lr (LM): 2.44e-06  max mem: 10867
11/16/2025 21:14:43 - INFO - __main__ -   eta: 1 day, 4:55:48  iter: 1360  global_step: 340  speed: 0.5 images/sec  loss: 8.2302 (9.5046)  acc: 0.0000 (0.0868)  batch_time: 0.4859 (0.4955)  data_time: 0.0004 (0.0045)  lr (Visual Encoder): 1.00e-08  lr (LM): 2.60e-06  max mem: 10867
11/16/2025 21:15:23 - INFO - __main__ -   eta: 1 day, 5:02:48  iter: 1440  global_step: 360  speed: 0.5 images/sec  loss: 8.4727 (9.4262)  acc: 0.0000 (0.0897)  batch_time: 0.4886 (0.4955)  data_time: 0.0005 (0.0043)  lr (Visual Encoder): 1.00e-08  lr (LM): 2.75e-06  max mem: 10867
11/16/2025 21:16:03 - INFO - __main__ -   eta: 1 day, 5:00:04  iter: 1520  global_step: 380  speed: 0.5 images/sec  loss: 9.2258 (9.3636)  acc: 0.0000 (0.0929)  batch_time: 0.4881 (0.4956)  data_time: 0.0005 (0.0041)  lr (Visual Encoder): 1.00e-08  lr (LM): 2.90e-06  max mem: 10867
11/16/2025 21:16:43 - INFO - __main__ -   eta: 1 day, 4:26:57  iter: 1600  global_step: 400  speed: 0.5 images/sec  loss: 8.2047 (9.2944)  acc: 0.0000 (0.0943)  batch_time: 0.4880 (0.4956)  data_time: 0.0004 (0.0039)  lr (Visual Encoder): 1.00e-08  lr (LM): 3.05e-06  max mem: 10867
11/16/2025 21:17:22 - INFO - __main__ -   eta: 1 day, 5:06:45  iter: 1680  global_step: 420  speed: 0.5 images/sec  loss: 7.5147 (9.2316)  acc: 0.0000 (0.0969)  batch_time: 0.4871 (0.4956)  data_time: 0.0005 (0.0037)  lr (Visual Encoder): 1.00e-08  lr (LM): 3.21e-06  max mem: 10867
11/16/2025 21:18:02 - INFO - __main__ -   eta: 1 day, 4:39:19  iter: 1760  global_step: 440  speed: 0.5 images/sec  loss: 7.8291 (9.1700)  acc: 0.0000 (0.0986)  batch_time: 0.4867 (0.4956)  data_time: 0.0005 (0.0036)  lr (Visual Encoder): 1.00e-08  lr (LM): 3.36e-06  max mem: 10867
11/16/2025 21:18:42 - INFO - __main__ -   eta: 1 day, 4:48:39  iter: 1840  global_step: 460  speed: 0.5 images/sec  loss: 8.2986 (9.1174)  acc: 0.0000 (0.1001)  batch_time: 0.4892 (0.4956)  data_time: 0.0004 (0.0034)  lr (Visual Encoder): 1.00e-08  lr (LM): 3.51e-06  max mem: 10867
11/16/2025 21:19:21 - INFO - __main__ -   eta: 1 day, 4:49:55  iter: 1920  global_step: 480  speed: 0.5 images/sec  loss: 8.7367 (9.0665)  acc: 0.0000 (0.1009)  batch_time: 0.4919 (0.4956)  data_time: 0.0005 (0.0033)  lr (Visual Encoder): 1.00e-08  lr (LM): 3.67e-06  max mem: 10867
11/16/2025 21:20:01 - INFO - __main__ -   eta: 1 day, 4:44:19  iter: 2000  global_step: 500  speed: 0.5 images/sec  loss: 8.5634 (9.0141)  acc: 0.0000 (0.1020)  batch_time: 0.4868 (0.4956)  data_time: 0.0005 (0.0032)  lr (Visual Encoder): 1.00e-08  lr (LM): 3.82e-06  max mem: 10867
11/16/2025 21:20:41 - INFO - __main__ -   eta: 1 day, 4:29:27  iter: 2080  global_step: 520  speed: 0.5 images/sec  loss: 7.4712 (8.9450)  acc: 0.0000 (0.1063)  batch_time: 0.4905 (0.4956)  data_time: 0.0004 (0.0031)  lr (Visual Encoder): 1.00e-08  lr (LM): 3.97e-06  max mem: 10867
11/16/2025 21:21:20 - INFO - __main__ -   eta: 1 day, 4:46:38  iter: 2160  global_step: 540  speed: 0.5 images/sec  loss: 8.4934 (8.8903)  acc: 0.0000 (0.1074)  batch_time: 0.4877 (0.4957)  data_time: 0.0005 (0.0030)  lr (Visual Encoder): 1.00e-08  lr (LM): 4.13e-06  max mem: 10867
11/16/2025 21:22:00 - INFO - __main__ -   eta: 1 day, 4:47:50  iter: 2240  global_step: 560  speed: 0.5 images/sec  loss: 6.4199 (8.8395)  acc: 0.0000 (0.1083)  batch_time: 0.4874 (0.4957)  data_time: 0.0005 (0.0029)  lr (Visual Encoder): 1.00e-08  lr (LM): 4.28e-06  max mem: 10867
11/16/2025 21:22:40 - INFO - __main__ -   eta: 1 day, 4:19:48  iter: 2320  global_step: 580  speed: 0.5 images/sec  loss: 7.3067 (8.7944)  acc: 0.0000 (0.1086)  batch_time: 0.4868 (0.4956)  data_time: 0.0005 (0.0028)  lr (Visual Encoder): 1.00e-08  lr (LM): 4.43e-06  max mem: 10867
11/16/2025 21:23:19 - INFO - __main__ -   eta: 1 day, 4:30:22  iter: 2400  global_step: 600  speed: 0.5 images/sec  loss: 6.5649 (8.7497)  acc: 0.0000 (0.1092)  batch_time: 0.4886 (0.4957)  data_time: 0.0005 (0.0027)  lr (Visual Encoder): 1.00e-08  lr (LM): 4.59e-06  max mem: 10867
11/16/2025 21:23:59 - INFO - __main__ -   eta: 1 day, 4:31:14  iter: 2480  global_step: 620  speed: 0.5 images/sec  loss: 5.9207 (8.6984)  acc: 0.0000 (0.1098)  batch_time: 0.4875 (0.4956)  data_time: 0.0005 (0.0027)  lr (Visual Encoder): 1.00e-08  lr (LM): 4.74e-06  max mem: 10867
11/16/2025 21:24:39 - INFO - __main__ -   eta: 1 day, 4:49:25  iter: 2560  global_step: 640  speed: 0.5 images/sec  loss: 8.2156 (8.6610)  acc: 0.0000 (0.1094)  batch_time: 0.4890 (0.4956)  data_time: 0.0005 (0.0026)  lr (Visual Encoder): 1.00e-08  lr (LM): 4.89e-06  max mem: 10867
11/16/2025 21:25:18 - INFO - __main__ -   eta: 1 day, 4:45:06  iter: 2640  global_step: 660  speed: 0.5 images/sec  loss: 7.7783 (8.6112)  acc: 0.0000 (0.1100)  batch_time: 0.4850 (0.4956)  data_time: 0.0005 (0.0025)  lr (Visual Encoder): 1.00e-08  lr (LM): 5.04e-06  max mem: 10867
11/16/2025 21:25:58 - INFO - __main__ -   eta: 1 day, 4:51:10  iter: 2720  global_step: 680  speed: 0.5 images/sec  loss: 6.1000 (8.5689)  acc: 0.0000 (0.1100)  batch_time: 0.4867 (0.4957)  data_time: 0.0005 (0.0025)  lr (Visual Encoder): 1.00e-08  lr (LM): 5.20e-06  max mem: 10867
11/16/2025 21:26:38 - INFO - __main__ -   eta: 1 day, 4:36:29  iter: 2800  global_step: 700  speed: 0.5 images/sec  loss: 6.1212 (8.5321)  acc: 0.0000 (0.1099)  batch_time: 0.4893 (0.4957)  data_time: 0.0005 (0.0024)  lr (Visual Encoder): 1.00e-08  lr (LM): 5.35e-06  max mem: 10867
11/16/2025 21:27:17 - INFO - __main__ -   eta: 1 day, 4:45:12  iter: 2880  global_step: 720  speed: 0.5 images/sec  loss: 6.2179 (8.4830)  acc: 0.0000 (0.1116)  batch_time: 0.4870 (0.4957)  data_time: 0.0004 (0.0024)  lr (Visual Encoder): 1.00e-08  lr (LM): 5.50e-06  max mem: 10867
11/16/2025 21:27:57 - INFO - __main__ -   eta: 1 day, 4:34:35  iter: 2960  global_step: 740  speed: 0.5 images/sec  loss: 6.6747 (8.4362)  acc: 0.0000 (0.1125)  batch_time: 0.4880 (0.4957)  data_time: 0.0005 (0.0023)  lr (Visual Encoder): 1.00e-08  lr (LM): 5.66e-06  max mem: 10867
11/16/2025 21:28:37 - INFO - __main__ -   eta: 1 day, 4:39:18  iter: 3040  global_step: 760  speed: 0.5 images/sec  loss: 7.1266 (8.3953)  acc: 0.0000 (0.1128)  batch_time: 0.4903 (0.4957)  data_time: 0.0005 (0.0023)  lr (Visual Encoder): 1.00e-08  lr (LM): 5.81e-06  max mem: 10867
11/16/2025 21:29:16 - INFO - __main__ -   eta: 1 day, 4:28:03  iter: 3120  global_step: 780  speed: 0.5 images/sec  loss: 6.6013 (8.3567)  acc: 0.0000 (0.1124)  batch_time: 0.4857 (0.4957)  data_time: 0.0005 (0.0022)  lr (Visual Encoder): 1.00e-08  lr (LM): 5.96e-06  max mem: 10867
11/16/2025 21:29:56 - INFO - __main__ -   eta: 1 day, 4:22:42  iter: 3200  global_step: 800  speed: 0.5 images/sec  loss: 7.2130 (8.3169)  acc: 0.0000 (0.1119)  batch_time: 0.4885 (0.4957)  data_time: 0.0004 (0.0022)  lr (Visual Encoder): 1.00e-08  lr (LM): 6.12e-06  max mem: 10867
11/16/2025 21:30:36 - INFO - __main__ -   eta: 1 day, 4:28:51  iter: 3280  global_step: 820  speed: 0.5 images/sec  loss: 7.8627 (8.2708)  acc: 0.0000 (0.1127)  batch_time: 0.4880 (0.4957)  data_time: 0.0004 (0.0021)  lr (Visual Encoder): 1.00e-08  lr (LM): 6.27e-06  max mem: 10867
11/16/2025 21:31:15 - INFO - __main__ -   eta: 1 day, 4:32:28  iter: 3360  global_step: 840  speed: 0.5 images/sec  loss: 5.7340 (8.2297)  acc: 0.0000 (0.1135)  batch_time: 0.4872 (0.4957)  data_time: 0.0004 (0.0021)  lr (Visual Encoder): 1.00e-08  lr (LM): 6.42e-06  max mem: 10867
11/16/2025 21:31:55 - INFO - __main__ -   eta: 1 day, 4:19:43  iter: 3440  global_step: 860  speed: 0.5 images/sec  loss: 5.7548 (8.1829)  acc: 0.0000 (0.1139)  batch_time: 0.4862 (0.4957)  data_time: 0.0005 (0.0020)  lr (Visual Encoder): 1.00e-08  lr (LM): 6.58e-06  max mem: 10867
11/16/2025 21:32:35 - INFO - __main__ -   eta: 1 day, 4:33:59  iter: 3520  global_step: 880  speed: 0.5 images/sec  loss: 6.0103 (8.1436)  acc: 0.0000 (0.1142)  batch_time: 0.4884 (0.4957)  data_time: 0.0005 (0.0020)  lr (Visual Encoder): 1.00e-08  lr (LM): 6.73e-06  max mem: 10867
11/16/2025 21:33:14 - INFO - __main__ -   eta: 1 day, 4:35:08  iter: 3600  global_step: 900  speed: 0.5 images/sec  loss: 5.1744 (8.1005)  acc: 0.0000 (0.1145)  batch_time: 0.4907 (0.4957)  data_time: 0.0005 (0.0020)  lr (Visual Encoder): 1.00e-08  lr (LM): 6.88e-06  max mem: 10867
11/16/2025 21:33:54 - INFO - __main__ -   eta: 1 day, 4:35:45  iter: 3680  global_step: 920  speed: 0.5 images/sec  loss: 6.0080 (8.0581)  acc: 0.0000 (0.1156)  batch_time: 0.4879 (0.4957)  data_time: 0.0005 (0.0019)  lr (Visual Encoder): 1.00e-08  lr (LM): 7.03e-06  max mem: 10867
11/16/2025 21:34:34 - INFO - __main__ -   eta: 1 day, 4:19:46  iter: 3760  global_step: 940  speed: 0.5 images/sec  loss: 5.0312 (8.0109)  acc: 0.0000 (0.1166)  batch_time: 0.4875 (0.4957)  data_time: 0.0004 (0.0019)  lr (Visual Encoder): 1.00e-08  lr (LM): 7.19e-06  max mem: 10867
11/16/2025 21:35:13 - INFO - __main__ -   eta: 1 day, 4:39:33  iter: 3840  global_step: 960  speed: 0.5 images/sec  loss: 6.0109 (7.9695)  acc: 0.0000 (0.1174)  batch_time: 0.4868 (0.4957)  data_time: 0.0005 (0.0019)  lr (Visual Encoder): 1.00e-08  lr (LM): 7.34e-06  max mem: 10867
11/16/2025 21:35:53 - INFO - __main__ -   eta: 1 day, 4:26:52  iter: 3920  global_step: 980  speed: 0.5 images/sec  loss: 6.2914 (7.9296)  acc: 0.0000 (0.1182)  batch_time: 0.4870 (0.4958)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.00e-08  lr (LM): 7.49e-06  max mem: 10867
11/16/2025 21:36:33 - INFO - __main__ -   eta: 1 day, 4:23:20  iter: 4000  global_step: 1000  speed: 0.5 images/sec  loss: 5.6720 (7.8898)  acc: 0.0000 (0.1183)  batch_time: 0.4870 (0.4958)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.00e-08  lr (LM): 7.65e-06  max mem: 10867
11/16/2025 21:37:13 - INFO - __main__ -   eta: 1 day, 4:12:28  iter: 4080  global_step: 1020  speed: 0.5 images/sec  loss: 4.8567 (7.8449)  acc: 0.0000 (0.1201)  batch_time: 0.4879 (0.4958)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.00e-08  lr (LM): 7.80e-06  max mem: 10867
11/16/2025 21:37:52 - INFO - __main__ -   eta: 1 day, 4:38:01  iter: 4160  global_step: 1040  speed: 0.5 images/sec  loss: 5.9724 (7.8052)  acc: 0.0000 (0.1208)  batch_time: 0.4917 (0.4958)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.00e-08  lr (LM): 7.95e-06  max mem: 10867
11/16/2025 21:38:32 - INFO - __main__ -   eta: 1 day, 4:22:24  iter: 4240  global_step: 1060  speed: 0.5 images/sec  loss: 5.8948 (7.7639)  acc: 0.0000 (0.1215)  batch_time: 0.4883 (0.4958)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.00e-08  lr (LM): 8.11e-06  max mem: 10867
11/16/2025 21:39:12 - INFO - __main__ -   eta: 1 day, 4:31:30  iter: 4320  global_step: 1080  speed: 0.5 images/sec  loss: 5.2580 (7.7207)  acc: 0.0000 (0.1227)  batch_time: 0.4887 (0.4958)  data_time: 0.0004 (0.0017)  lr (Visual Encoder): 1.00e-08  lr (LM): 8.26e-06  max mem: 10867
11/16/2025 21:39:51 - INFO - __main__ -   eta: 1 day, 4:23:32  iter: 4400  global_step: 1100  speed: 0.5 images/sec  loss: 5.2591 (7.6836)  acc: 0.0000 (0.1233)  batch_time: 0.4889 (0.4958)  data_time: 0.0004 (0.0017)  lr (Visual Encoder): 1.00e-08  lr (LM): 8.41e-06  max mem: 10867
11/16/2025 21:40:31 - INFO - __main__ -   eta: 1 day, 4:23:17  iter: 4480  global_step: 1120  speed: 0.5 images/sec  loss: 5.6538 (7.6473)  acc: 0.0000 (0.1237)  batch_time: 0.4872 (0.4958)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.00e-08  lr (LM): 8.57e-06  max mem: 10867
11/16/2025 21:41:11 - INFO - __main__ -   eta: 1 day, 4:30:08  iter: 4560  global_step: 1140  speed: 0.5 images/sec  loss: 5.3447 (7.6125)  acc: 0.0000 (0.1242)  batch_time: 0.4900 (0.4958)  data_time: 0.0005 (0.0016)  lr (Visual Encoder): 1.00e-08  lr (LM): 8.72e-06  max mem: 10867
11/16/2025 21:41:51 - INFO - __main__ -   eta: 1 day, 4:28:23  iter: 4640  global_step: 1160  speed: 0.5 images/sec  loss: 5.0782 (7.5701)  acc: 0.0000 (0.1251)  batch_time: 0.4874 (0.4959)  data_time: 0.0005 (0.0016)  lr (Visual Encoder): 1.00e-08  lr (LM): 8.87e-06  max mem: 10867
11/16/2025 21:42:30 - INFO - __main__ -   eta: 1 day, 3:51:25  iter: 4720  global_step: 1180  speed: 0.5 images/sec  loss: 4.6137 (7.5324)  acc: 0.0000 (0.1262)  batch_time: 0.4888 (0.4959)  data_time: 0.0005 (0.0016)  lr (Visual Encoder): 1.00e-08  lr (LM): 9.03e-06  max mem: 10867
11/16/2025 21:43:11 - INFO - __main__ -   eta: 3 days, 5:05:13  iter: 4800  global_step: 1200  speed: 0.5 images/sec  loss: 5.8549 (7.4988)  acc: 0.0000 (0.1273)  batch_time: 0.4865 (0.4959)  data_time: 0.0005 (0.0016)  lr (Visual Encoder): 1.00e-08  lr (LM): 9.18e-06  max mem: 10867
11/16/2025 21:43:51 - INFO - __main__ -   eta: 1 day, 4:22:11  iter: 4880  global_step: 1220  speed: 0.5 images/sec  loss: 5.6981 (7.4701)  acc: 0.0000 (0.1278)  batch_time: 0.4883 (0.4961)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.00e-08  lr (LM): 9.33e-06  max mem: 10867
11/16/2025 21:44:31 - INFO - __main__ -   eta: 1 day, 4:16:00  iter: 4960  global_step: 1240  speed: 0.5 images/sec  loss: 5.0218 (7.4396)  acc: 0.0000 (0.1281)  batch_time: 0.4893 (0.4961)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.00e-08  lr (LM): 9.48e-06  max mem: 10867
11/16/2025 21:45:10 - INFO - __main__ -   eta: 1 day, 4:11:23  iter: 5040  global_step: 1260  speed: 0.5 images/sec  loss: 5.3373 (7.4084)  acc: 0.0000 (0.1285)  batch_time: 0.4895 (0.4961)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.00e-08  lr (LM): 9.64e-06  max mem: 10867
11/16/2025 21:45:50 - INFO - __main__ -   eta: 1 day, 4:17:59  iter: 5120  global_step: 1280  speed: 0.5 images/sec  loss: 5.0126 (7.3751)  acc: 0.0000 (0.1288)  batch_time: 0.4854 (0.4961)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.00e-08  lr (LM): 9.79e-06  max mem: 10867
11/16/2025 21:46:30 - INFO - __main__ -   eta: 1 day, 4:13:23  iter: 5200  global_step: 1300  speed: 0.5 images/sec  loss: 5.5877 (7.3383)  acc: 0.0000 (0.1297)  batch_time: 0.4876 (0.4961)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.00e-08  lr (LM): 9.94e-06  max mem: 10867
11/16/2025 21:47:09 - INFO - __main__ -   eta: 1 day, 4:14:13  iter: 5280  global_step: 1320  speed: 0.5 images/sec  loss: 6.9877 (7.3119)  acc: 0.0000 (0.1300)  batch_time: 0.4886 (0.4961)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.01e-08  lr (LM): 1.01e-05  max mem: 10867
11/16/2025 21:47:49 - INFO - __main__ -   eta: 1 day, 4:09:28  iter: 5360  global_step: 1340  speed: 0.5 images/sec  loss: 4.4921 (7.2757)  acc: 0.0000 (0.1312)  batch_time: 0.4917 (0.4961)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.03e-08  lr (LM): 1.03e-05  max mem: 10867
11/16/2025 21:48:29 - INFO - __main__ -   eta: 1 day, 3:59:47  iter: 5440  global_step: 1360  speed: 0.5 images/sec  loss: 4.9563 (7.2484)  acc: 0.0000 (0.1315)  batch_time: 0.4887 (0.4962)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.04e-08  lr (LM): 1.04e-05  max mem: 10867
11/16/2025 21:49:09 - INFO - __main__ -   eta: 1 day, 4:18:28  iter: 5520  global_step: 1380  speed: 0.5 images/sec  loss: 4.9045 (7.2192)  acc: 0.0000 (0.1318)  batch_time: 0.4883 (0.4962)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.06e-08  lr (LM): 1.06e-05  max mem: 10867
11/16/2025 21:49:48 - INFO - __main__ -   eta: 1 day, 4:19:23  iter: 5600  global_step: 1400  speed: 0.5 images/sec  loss: 5.2985 (7.1841)  acc: 0.0000 (0.1327)  batch_time: 0.4897 (0.4962)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.07e-08  lr (LM): 1.07e-05  max mem: 10867
11/16/2025 21:50:28 - INFO - __main__ -   eta: 1 day, 4:05:40  iter: 5680  global_step: 1420  speed: 0.5 images/sec  loss: 4.6710 (7.1561)  acc: 0.0000 (0.1331)  batch_time: 0.4895 (0.4962)  data_time: 0.0005 (0.0016)  lr (Visual Encoder): 1.09e-08  lr (LM): 1.09e-05  max mem: 10867
11/16/2025 21:51:08 - INFO - __main__ -   eta: 1 day, 4:12:30  iter: 5760  global_step: 1440  speed: 0.5 images/sec  loss: 5.6257 (7.1294)  acc: 0.0000 (0.1337)  batch_time: 0.4870 (0.4962)  data_time: 0.0005 (0.0016)  lr (Visual Encoder): 1.10e-08  lr (LM): 1.10e-05  max mem: 10867
11/16/2025 21:51:48 - INFO - __main__ -   eta: 1 day, 4:04:03  iter: 5840  global_step: 1460  speed: 0.5 images/sec  loss: 4.7578 (7.1021)  acc: 0.0000 (0.1335)  batch_time: 0.4883 (0.4962)  data_time: 0.0005 (0.0016)  lr (Visual Encoder): 1.12e-08  lr (LM): 1.12e-05  max mem: 10867
11/16/2025 21:52:27 - INFO - __main__ -   eta: 1 day, 3:50:12  iter: 5920  global_step: 1480  speed: 0.5 images/sec  loss: 4.9253 (7.0685)  acc: 0.0000 (0.1349)  batch_time: 0.4900 (0.4962)  data_time: 0.0005 (0.0016)  lr (Visual Encoder): 1.13e-08  lr (LM): 1.13e-05  max mem: 10867
11/16/2025 21:53:11 - INFO - __main__ -   eta: 1 day, 4:14:05  iter: 6000  global_step: 1500  speed: 0.5 images/sec  loss: 4.6196 (7.0443)  acc: 0.0000 (0.1351)  batch_time: 0.4940 (0.4968)  data_time: 0.0005 (0.0022)  lr (Visual Encoder): 1.15e-08  lr (LM): 1.15e-05  max mem: 10867
11/16/2025 21:53:50 - INFO - __main__ -   eta: 1 day, 4:10:44  iter: 6080  global_step: 1520  speed: 0.5 images/sec  loss: 5.0853 (7.0166)  acc: 0.0000 (0.1356)  batch_time: 0.4867 (0.4968)  data_time: 0.0005 (0.0022)  lr (Visual Encoder): 1.16e-08  lr (LM): 1.16e-05  max mem: 10867
11/16/2025 21:54:30 - INFO - __main__ -   eta: 1 day, 4:19:19  iter: 6160  global_step: 1540  speed: 0.5 images/sec  loss: 4.6699 (6.9929)  acc: 0.0000 (0.1356)  batch_time: 0.4917 (0.4968)  data_time: 0.0005 (0.0021)  lr (Visual Encoder): 1.18e-08  lr (LM): 1.18e-05  max mem: 10867
11/16/2025 21:55:10 - INFO - __main__ -   eta: 1 day, 4:16:21  iter: 6240  global_step: 1560  speed: 0.5 images/sec  loss: 4.8220 (6.9716)  acc: 0.0000 (0.1354)  batch_time: 0.4886 (0.4968)  data_time: 0.0005 (0.0021)  lr (Visual Encoder): 1.19e-08  lr (LM): 1.19e-05  max mem: 10867
11/16/2025 21:55:50 - INFO - __main__ -   eta: 1 day, 3:59:03  iter: 6320  global_step: 1580  speed: 0.5 images/sec  loss: 5.2328 (6.9500)  acc: 0.0000 (0.1356)  batch_time: 0.4866 (0.4968)  data_time: 0.0004 (0.0021)  lr (Visual Encoder): 1.21e-08  lr (LM): 1.21e-05  max mem: 10867
11/16/2025 21:56:29 - INFO - __main__ -   eta: 1 day, 4:17:40  iter: 6400  global_step: 1600  speed: 0.5 images/sec  loss: 4.7213 (6.9244)  acc: 0.0000 (0.1360)  batch_time: 0.4888 (0.4968)  data_time: 0.0005 (0.0021)  lr (Visual Encoder): 1.22e-08  lr (LM): 1.22e-05  max mem: 10867
11/16/2025 21:57:09 - INFO - __main__ -   eta: 1 day, 4:05:48  iter: 6480  global_step: 1620  speed: 0.5 images/sec  loss: 4.1601 (6.8990)  acc: 0.0000 (0.1365)  batch_time: 0.4881 (0.4968)  data_time: 0.0005 (0.0020)  lr (Visual Encoder): 1.24e-08  lr (LM): 1.24e-05  max mem: 10867
11/16/2025 21:57:49 - INFO - __main__ -   eta: 1 day, 3:59:13  iter: 6560  global_step: 1640  speed: 0.5 images/sec  loss: 4.1637 (6.8745)  acc: 0.0000 (0.1367)  batch_time: 0.4873 (0.4968)  data_time: 0.0005 (0.0020)  lr (Visual Encoder): 1.25e-08  lr (LM): 1.25e-05  max mem: 10867
11/16/2025 21:58:29 - INFO - __main__ -   eta: 1 day, 3:55:57  iter: 6640  global_step: 1660  speed: 0.5 images/sec  loss: 4.3643 (6.8509)  acc: 0.0000 (0.1373)  batch_time: 0.4910 (0.4968)  data_time: 0.0005 (0.0020)  lr (Visual Encoder): 1.27e-08  lr (LM): 1.27e-05  max mem: 10867
11/16/2025 21:59:08 - INFO - __main__ -   eta: 1 day, 4:17:07  iter: 6720  global_step: 1680  speed: 0.5 images/sec  loss: 5.4880 (6.8290)  acc: 0.0000 (0.1381)  batch_time: 0.4880 (0.4968)  data_time: 0.0005 (0.0020)  lr (Visual Encoder): 1.29e-08  lr (LM): 1.29e-05  max mem: 10867
11/16/2025 21:59:48 - INFO - __main__ -   eta: 1 day, 4:06:15  iter: 6800  global_step: 1700  speed: 0.5 images/sec  loss: 5.0623 (6.8032)  acc: 0.0000 (0.1379)  batch_time: 0.4885 (0.4968)  data_time: 0.0004 (0.0020)  lr (Visual Encoder): 1.30e-08  lr (LM): 1.30e-05  max mem: 10867
11/16/2025 22:00:28 - INFO - __main__ -   eta: 1 day, 3:54:58  iter: 6880  global_step: 1720  speed: 0.5 images/sec  loss: 3.4534 (6.7828)  acc: 0.0000 (0.1384)  batch_time: 0.4886 (0.4968)  data_time: 0.0004 (0.0020)  lr (Visual Encoder): 1.32e-08  lr (LM): 1.32e-05  max mem: 10867
11/16/2025 22:01:07 - INFO - __main__ -   eta: 1 day, 3:55:37  iter: 6960  global_step: 1740  speed: 0.5 images/sec  loss: 3.7472 (6.7558)  acc: 0.3333 (0.1390)  batch_time: 0.4875 (0.4968)  data_time: 0.0004 (0.0019)  lr (Visual Encoder): 1.33e-08  lr (LM): 1.33e-05  max mem: 10867
11/16/2025 22:01:47 - INFO - __main__ -   eta: 1 day, 4:00:30  iter: 7040  global_step: 1760  speed: 0.5 images/sec  loss: 3.9184 (6.7360)  acc: 0.3333 (0.1396)  batch_time: 0.4883 (0.4968)  data_time: 0.0005 (0.0019)  lr (Visual Encoder): 1.35e-08  lr (LM): 1.35e-05  max mem: 10867
11/16/2025 22:02:27 - INFO - __main__ -   eta: 1 day, 3:47:43  iter: 7120  global_step: 1780  speed: 0.5 images/sec  loss: 4.4588 (6.7147)  acc: 0.0000 (0.1401)  batch_time: 0.4872 (0.4968)  data_time: 0.0005 (0.0019)  lr (Visual Encoder): 1.36e-08  lr (LM): 1.36e-05  max mem: 10867
11/16/2025 22:03:07 - INFO - __main__ -   eta: 1 day, 3:47:01  iter: 7200  global_step: 1800  speed: 0.5 images/sec  loss: 4.8519 (6.6966)  acc: 0.0000 (0.1405)  batch_time: 0.4870 (0.4968)  data_time: 0.0005 (0.0019)  lr (Visual Encoder): 1.38e-08  lr (LM): 1.38e-05  max mem: 10867
11/16/2025 22:03:47 - INFO - __main__ -   eta: 1 day, 3:55:54  iter: 7280  global_step: 1820  speed: 0.5 images/sec  loss: 6.3245 (6.6772)  acc: 0.0000 (0.1405)  batch_time: 0.4882 (0.4968)  data_time: 0.0005 (0.0019)  lr (Visual Encoder): 1.39e-08  lr (LM): 1.39e-05  max mem: 10867
11/16/2025 22:04:26 - INFO - __main__ -   eta: 1 day, 3:48:26  iter: 7360  global_step: 1840  speed: 0.5 images/sec  loss: 3.6806 (6.6555)  acc: 0.3333 (0.1413)  batch_time: 0.4913 (0.4968)  data_time: 0.0005 (0.0019)  lr (Visual Encoder): 1.41e-08  lr (LM): 1.41e-05  max mem: 10867
11/16/2025 22:05:06 - INFO - __main__ -   eta: 1 day, 3:54:08  iter: 7440  global_step: 1860  speed: 0.5 images/sec  loss: 5.3309 (6.6355)  acc: 0.0000 (0.1419)  batch_time: 0.4888 (0.4968)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.42e-08  lr (LM): 1.42e-05  max mem: 10867
11/16/2025 22:05:46 - INFO - __main__ -   eta: 1 day, 3:46:14  iter: 7520  global_step: 1880  speed: 0.5 images/sec  loss: 5.0487 (6.6154)  acc: 0.0000 (0.1426)  batch_time: 0.4891 (0.4968)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.44e-08  lr (LM): 1.44e-05  max mem: 10867
11/16/2025 22:06:26 - INFO - __main__ -   eta: 1 day, 3:41:32  iter: 7600  global_step: 1900  speed: 0.5 images/sec  loss: 3.8795 (6.5958)  acc: 0.0000 (0.1426)  batch_time: 0.4896 (0.4968)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.45e-08  lr (LM): 1.45e-05  max mem: 10867
11/16/2025 22:07:06 - INFO - __main__ -   eta: 1 day, 3:46:40  iter: 7680  global_step: 1920  speed: 0.5 images/sec  loss: 4.1332 (6.5810)  acc: 0.0000 (0.1424)  batch_time: 0.4867 (0.4968)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.47e-08  lr (LM): 1.47e-05  max mem: 10867
11/16/2025 22:07:45 - INFO - __main__ -   eta: 1 day, 3:57:02  iter: 7760  global_step: 1940  speed: 0.5 images/sec  loss: 4.9326 (6.5668)  acc: 0.0000 (0.1424)  batch_time: 0.4886 (0.4968)  data_time: 0.0004 (0.0018)  lr (Visual Encoder): 1.48e-08  lr (LM): 1.48e-05  max mem: 10867
11/16/2025 22:08:23 - INFO - __main__ -   TrainingRestorer save trial NO. 0
11/16/2025 22:08:25 - INFO - __main__ -   TrainingRestorer save trial NO. 1
11/16/2025 22:08:26 - INFO - __main__ -   TrainingRestorer save trial NO. 2
11/16/2025 22:08:27 - INFO - __main__ -   TrainingRestorer save trial NO. 3
11/16/2025 22:08:28 - INFO - __main__ -   TrainingRestorer save trial NO. 4
11/16/2025 22:08:30 - INFO - __main__ -   TrainingRestorer save trial NO. 5
11/16/2025 22:08:31 - INFO - __main__ -   TrainingRestorer save trial NO. 6
11/16/2025 22:08:32 - INFO - __main__ -   TrainingRestorer save trial NO. 7
11/16/2025 22:08:33 - INFO - __main__ -   TrainingRestorer save trial NO. 8
11/16/2025 22:08:35 - INFO - __main__ -   TrainingRestorer save trial NO. 9
11/16/2025 22:08:38 - INFO - __main__ -   eta: 1 day, 3:42:47  iter: 7840  global_step: 1960  speed: 0.4 images/sec  loss: 4.6883 (6.5500)  acc: 0.0000 (0.1428)  batch_time: 0.4878 (0.4984)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.50e-08  lr (LM): 1.50e-05  max mem: 10867
11/16/2025 22:09:17 - INFO - __main__ -   eta: 1 day, 3:48:47  iter: 7920  global_step: 1980  speed: 0.5 images/sec  loss: 5.1628 (6.5318)  acc: 0.0000 (0.1431)  batch_time: 0.4879 (0.4984)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.51e-08  lr (LM): 1.51e-05  max mem: 10867
11/16/2025 22:09:57 - INFO - __main__ -   eta: 1 day, 3:59:35  iter: 8000  global_step: 2000  speed: 0.5 images/sec  loss: 3.4526 (6.5129)  acc: 0.0000 (0.1438)  batch_time: 0.4883 (0.4984)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.53e-08  lr (LM): 1.53e-05  max mem: 10867
11/16/2025 22:10:36 - INFO - __main__ -   eta: 1 day, 3:48:38  iter: 8080  global_step: 2020  speed: 0.5 images/sec  loss: 4.9700 (6.4966)  acc: 0.0000 (0.1443)  batch_time: 0.4889 (0.4983)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.55e-08  lr (LM): 1.55e-05  max mem: 10867
11/16/2025 22:11:17 - INFO - __main__ -   eta: 1 day, 3:41:51  iter: 8160  global_step: 2040  speed: 0.5 images/sec  loss: 5.2575 (6.4888)  acc: 0.3333 (0.1444)  batch_time: 0.4881 (0.4984)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.56e-08  lr (LM): 1.56e-05  max mem: 10867
11/16/2025 22:11:57 - INFO - __main__ -   eta: 1 day, 3:46:59  iter: 8240  global_step: 2060  speed: 0.5 images/sec  loss: 4.0528 (6.4761)  acc: 0.0000 (0.1446)  batch_time: 0.4863 (0.4984)  data_time: 0.0004 (0.0018)  lr (Visual Encoder): 1.58e-08  lr (LM): 1.58e-05  max mem: 10867
11/16/2025 22:12:36 - INFO - __main__ -   eta: 1 day, 3:34:40  iter: 8320  global_step: 2080  speed: 0.5 images/sec  loss: 5.2466 (6.4626)  acc: 0.0000 (0.1447)  batch_time: 0.4886 (0.4984)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.59e-08  lr (LM): 1.59e-05  max mem: 10867
11/16/2025 22:13:16 - INFO - __main__ -   eta: 1 day, 3:35:34  iter: 8400  global_step: 2100  speed: 0.5 images/sec  loss: 4.2918 (6.4488)  acc: 0.0000 (0.1447)  batch_time: 0.4899 (0.4984)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.61e-08  lr (LM): 1.61e-05  max mem: 10867
11/16/2025 22:13:56 - INFO - __main__ -   eta: 1 day, 3:52:06  iter: 8480  global_step: 2120  speed: 0.5 images/sec  loss: 4.4592 (6.4325)  acc: 0.0000 (0.1448)  batch_time: 0.4881 (0.4984)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.62e-08  lr (LM): 1.62e-05  max mem: 10867
11/16/2025 22:14:36 - INFO - __main__ -   eta: 1 day, 3:44:41  iter: 8560  global_step: 2140  speed: 0.5 images/sec  loss: 3.4184 (6.4137)  acc: 0.0000 (0.1452)  batch_time: 0.4898 (0.4983)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.64e-08  lr (LM): 1.64e-05  max mem: 10867
11/16/2025 22:15:16 - INFO - __main__ -   eta: 1 day, 3:38:15  iter: 8640  global_step: 2160  speed: 0.5 images/sec  loss: 4.5231 (6.3997)  acc: 0.0000 (0.1454)  batch_time: 0.4912 (0.4983)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.65e-08  lr (LM): 1.65e-05  max mem: 10867
11/16/2025 22:15:55 - INFO - __main__ -   eta: 1 day, 3:36:55  iter: 8720  global_step: 2180  speed: 0.5 images/sec  loss: 3.4246 (6.3847)  acc: 0.0000 (0.1458)  batch_time: 0.4896 (0.4983)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.67e-08  lr (LM): 1.67e-05  max mem: 10867
11/16/2025 22:16:35 - INFO - __main__ -   eta: 1 day, 3:41:20  iter: 8800  global_step: 2200  speed: 0.5 images/sec  loss: 5.8207 (6.3701)  acc: 0.0000 (0.1466)  batch_time: 0.4889 (0.4983)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.68e-08  lr (LM): 1.68e-05  max mem: 10867
11/16/2025 22:17:15 - INFO - __main__ -   eta: 1 day, 3:41:41  iter: 8880  global_step: 2220  speed: 0.5 images/sec  loss: 5.1777 (6.3551)  acc: 0.0000 (0.1466)  batch_time: 0.4892 (0.4983)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.70e-08  lr (LM): 1.70e-05  max mem: 10867
11/16/2025 22:17:55 - INFO - __main__ -   eta: 1 day, 3:18:18  iter: 8960  global_step: 2240  speed: 0.5 images/sec  loss: 4.5442 (6.3386)  acc: 0.0000 (0.1474)  batch_time: 0.4862 (0.4983)  data_time: 0.0005 (0.0018)  lr (Visual Encoder): 1.71e-08  lr (LM): 1.71e-05  max mem: 10867
11/16/2025 22:18:35 - INFO - __main__ -   eta: 1 day, 3:30:09  iter: 9040  global_step: 2260  speed: 0.5 images/sec  loss: 4.7400 (6.3243)  acc: 0.0000 (0.1476)  batch_time: 0.4885 (0.4983)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.73e-08  lr (LM): 1.73e-05  max mem: 10867
11/16/2025 22:19:15 - INFO - __main__ -   eta: 1 day, 3:32:57  iter: 9120  global_step: 2280  speed: 0.5 images/sec  loss: 3.4564 (6.3085)  acc: 0.3333 (0.1485)  batch_time: 0.4924 (0.4983)  data_time: 0.0005 (0.0017)  lr (Visual Encoder): 1.74e-08  lr (LM): 1.74e-05  max mem: 10867
11/16/2025 22:20:11 - INFO - __main__ -   eta: 1 day, 3:22:01  iter: 9200  global_step: 2300  speed: 0.4 images/sec  loss: 4.3161 (6.2964)  acc: 0.3333 (0.1490)  batch_time: 0.4826 (0.5001)  data_time: 0.0004 (0.0036)  lr (Visual Encoder): 1.76e-08  lr (LM): 1.76e-05  max mem: 10867
11/16/2025 22:20:51 - INFO - __main__ -   eta: 1 day, 3:13:25  iter: 9280  global_step: 2320  speed: 0.5 images/sec  loss: 3.8433 (6.2834)  acc: 0.0000 (0.1491)  batch_time: 0.4875 (0.5001)  data_time: 0.0005 (0.0035)  lr (Visual Encoder): 1.78e-08  lr (LM): 1.78e-05  max mem: 10867
11/16/2025 22:21:32 - INFO - __main__ -   eta: 1 day, 3:28:11  iter: 9360  global_step: 2340  speed: 0.5 images/sec  loss: 3.7558 (6.2707)  acc: 0.0000 (0.1495)  batch_time: 0.4856 (0.5002)  data_time: 0.0003 (0.0037)  lr (Visual Encoder): 1.79e-08  lr (LM): 1.79e-05  max mem: 10867
11/16/2025 22:22:12 - INFO - __main__ -   eta: 1 day, 3:29:18  iter: 9440  global_step: 2360  speed: 0.5 images/sec  loss: 4.1393 (6.2546)  acc: 0.0000 (0.1501)  batch_time: 0.4876 (0.5002)  data_time: 0.0005 (0.0037)  lr (Visual Encoder): 1.81e-08  lr (LM): 1.81e-05  max mem: 10867
